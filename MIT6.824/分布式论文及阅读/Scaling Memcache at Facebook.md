# Scaling Memcache at Facebook

## thundering herds

在计算机系统和网络领域中，"雷鸣般的兽群"（thundering herds）是指在多个进程或线程等待某个共享资源（如锁或网络连接）可用时可能出现的性能问题。

"雷鸣般的兽群"一词源于大量动物（如水牛或角马）同时向一个资源冲击的类比。在计算机系统中，它描述了大量进程或线程同时被唤醒或触发的情况，从而产生了一阵活动，使系统不堪重负。

雷鸣般的兽群问题通常出现在多个进程或线程等待特定事件或条件发生的情况下，比如等待锁释放或网络连接建立。当这个事件或条件达到时，所有等待的进程或线程同时被唤醒，并竞争使用资源。这可能导致系统负载突然增加，处理请求的延迟增加，甚至引发系统崩溃或性能下降。

为了解决雷鸣般的兽群问题，可以采取一些策略。其中一种常见的方法是引入随机化延迟，使等待的进程或线程在一定时间间隔内随机唤醒，从而分散竞争。另外，可以使用更高效的同步机制或调度算法，以减少资源竞争的可能性，或者采用负载均衡策略，将请求分散到多个可用资源上。

总之，雷鸣般的兽群问题是指在多个进程或线程等待共享资源可用时可能出现的性能问题，需要采取合适的策略来减轻竞争压力，保证系统的稳定性和性能。

**总结：多进程或线程等待共享资源所产生的性能影响**

## stale sets

过时集（stale sets）是在分布式系统中用于跟踪和管理过时数据的数据结构。过时数据是指已过时或不再反映最新更新或更改的数据。

在分布式系统中，数据为了可用性和容错性会被复制到多个节点或分区中，确保数据一致性可能具有挑战性。过时集通过识别和跟踪过时数据来解决这个挑战。

过时集通常维护一个包含被认为是过时的数据项或版本号的列表。这些数据项可以是单个记录、文档或任何其他数据单元。当系统中的数据被修改或更新时，过时集会进行更新。

当客户端或应用程序从分布式系统中访问数据时，可以查询过时集来确定所检索的数据是否是最新的或可能过时的。如果数据在集合中被标记为过时，客户端可以采取适当的操作，例如获取最新版本的数据或从权威源请求更新。

过时集的实现和管理方式因具体要求和分布式系统的设计而异。一些方法涉及维护一个集中化的过时集，而其他方法可能将过时集分布在系统中的多个节点上。

通过使用过时集，分布式系统可以提供检测和处理过时数据的机制，确保客户端和应用程序能够访问最新的和一致的数据。管理过时性对于在分布式环境中维护数据的完整性和正确性非常重要。

**总结：检测过时数据以及不在更改数据，保证一致性**

## Look-aside Cache，LAC

查找旁路缓存（Look-aside Cache，LAC）是一种在计算机系统中用于提高对频繁访问数据的访问速度的缓存技术。它通常在涉及磁盘存储或数据库操作的系统中使用。

在查找旁路缓存中，与主要数据存储或处理系统分开维护一个缓存。当收到对数据的请求时，系统首先检查缓存中是否存在该数据。如果数据存在于缓存中（缓存命中），可以快速检索并将其返回给请求者，而无需访问主要存储系统，从而显著提高性能。

然而，如果请求的数据不在缓存中（缓存未命中），则系统必须访问主要存储系统获取数据，并将其存储到缓存中以供将来使用。这样，在后续的请求中，如果相同的数据再次被请求，就可以从缓存中快速获取，减少对主要存储系统的访问次数。

查找旁路缓存的优点是可以减少对主要存储系统的访问延迟，提高数据访问速度。它特别适用于具有大量读取操作和访问模式重复性的场景，因为这些操作可以从快速的缓存中获取数据，而无需每次都访问较慢的主要存储系统。

需要注意的是，查找旁路缓存需要一定的缓存管理策略，以确保缓存中的数据与主要存储系统中的数据保持一致性。常见的策略包括使用缓存失效机制、缓存淘汰算法等。

总结而言，查找旁路缓存是一种用于提高数据访问速度的缓存技术，通过将频繁访问的数据存储在快速的缓存中，减少对主要存储系统的访问，从而提高系统性能。

**总结：在内存中维护一个经常访问的数据的缓存，每次先访问缓存，找不到再访问数据库。用来显著提高访问性能。**

## Inline Cache

内联缓存（Inline Cache）是一种用于优化方法调用的缓存技术。它通常用于动态语言解释器或即时编译器中，以加速方法调用的执行。

内联缓存的目标是通过缓存先前的方法调用的结果，避免重复的动态查找和解析过程，从而提高方法调用的性能。当一个方法被调用时，解释器或编译器会检查内联缓存以查找之前对相同方法的调用是否已经存在缓存中。

如果方法调用的缓存命中，即之前已经对该方法进行过调用并且缓存了结果，那么执行过程可以直接使用缓存中的结果，而不需要再次执行查找和解析操作。这大大减少了执行过程中的开销，提高了方法调用的性能。

然而，如果方法调用的缓存未命中，即该方法之前没有进行过调用或者缓存已经失效，那么解释器或编译器将执行标准的方法调用过程，包括查找和解析方法的定义，执行方法体等操作。同时，还会更新内联缓存，以便下一次对相同方法的调用可以从缓存中获取结果。

内联缓存的使用可以减少方法调用过程中的动态查找和解析开销，提高方法调用的效率。通过缓存先前的调用结果，可以避免重复执行相同的查找和解析操作，从而节省了时间和计算资源。

总结而言，内联缓存是一种用于优化方法调用的缓存技术，通过缓存先前的方法调用结果，避免重复的查找和解析过程，提高方法调用的性能。它在动态语言解释器和即时编译器中被广泛使用。

**总结：优化方法调用的缓存技术，每次访问必定先经过缓存，穿行化，顺序访问缓存和数据库**

## incast congestion

Incast congestion（突发拥塞）是指在计算机网络中，当多个客户端同时向同一个服务器发送请求或数据时，导致网络链路或服务器端口出现临时的拥塞现象。这种情况通常发生在分布式系统或数据中心环境中，当多个客户端同时请求相同的资源或执行相同的操作时。

当多个客户端同时向服务器发送请求时，这些请求可能会在网络中的某个瓶颈点（如交换机、路由器或链路）聚集在一起，形成一个突发的高峰流量。这种聚集会导致网络链路或服务器端口的带宽被瞬间占用，造成拥塞现象。

Incast congestion 可能会导致以下问题：

1. 延迟增加：由于网络链路或服务器端口被过多的请求占用，导致请求的响应时间增加，客户端等待时间延长，从而增加整体延迟。
2. 丢包增加：当网络链路或服务器端口达到其容量极限时，可能会发生丢包现象。这可能导致请求失败或数据丢失，需要进行重新传输或处理。
3. 不公平性：如果拥塞发生在网络链路上，其他未涉及到拥塞的流量可能会受到影响，导致不公平的资源分配。

为了缓解 incast congestion，可以采取以下一些措施：

1. 缓冲区管理：增加网络设备的缓冲区大小，可以暂时存储突发流量，降低丢包率。
2. 流量调度：使用合适的流量调度算法，如加权公平队列（Weighted Fair Queueing）或公平拥塞控制（Fair Congestion Control），以公平地分配网络资源。
3. 拥塞控制：在客户端和服务器端实施拥塞控制机制，例如减小发送窗口大小、增加超时时间等，以减少突发流量对网络的影响。
4. 负载均衡：通过使用负载均衡器将请求分散到多个服务器上，可以减轻单个服务器的负载，降低发生拥塞的概率。

通过采取这些措施，可以降低 incast congestion 的发生概率，提高系统的性能和可靠性。

**总结：服务器突然接收的统一资源请求过多所造成的拥塞**

## Hold-off

"Hold-off" 是一个术语，用于描述在某种情况下推迟或延迟采取行动或做出决策的行为或策略。

在不同的上下文中，"hold-off" 可以有不同的含义和应用：

1. 网络通信中的 Hold-off：在网络通信中，Hold-off 是指在发送数据包或请求之间的一段延迟时间。这种延迟通常用于避免网络拥塞或过载，以确保网络的稳定性和吞吐量。
2. 决策和行动的 Hold-off：在管理和决策过程中，Hold-off 是指推迟做出决策或行动的策略。这可能是为了等待更多的信息、评估风险或获得更好的理解。Hold-off 可以用于避免草率的决策，允许更全面和深入的分析，并确保更好的决策结果。
3. 电子系统中的 Hold-off：在电子系统中，Hold-off 是指在某些条件下推迟或延迟电路或设备的操作或功能。这可以是为了满足特定的时序要求、保护电路免受干扰或确保正确的信号处理。

总的来说，"hold-off" 是一个通用的术语，用于描述延迟或推迟行动或决策的策略。具体应用和含义取决于所讨论的上下文和领域。

**总结：删除延迟**







****

**[来源：ChatGPT]**