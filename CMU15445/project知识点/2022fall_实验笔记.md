# 2022fall_实验笔记

## project_0 - trie tree

### 实验目的

* 实现一个存储字符串的 `trie` 树，同一个单词的同一个位置如果字母相同，使用同一个 `node`，最终的节点存储字符串键对应的 `value`，用来判断。

### 实验内容

* 根据数据结构需要实现三个部分：
  * `TrieNode` 类：trie 树的每个基本的节点
  * `TrieNodeWithValue` 类：`TrieNode` 的子类，用于表示每个单词结尾字母的 `kv` 结构
  * `Trie` 类：用于组织节点，并不同于存储任何 `kv`，增删改查。注意不允许插入重复的键。
  * 并发操作：通过加入 lock 实现 `trie` 树的并发

### 实现要点

#### TrieNode

* 类的初始化
  * 初始化节点存储的 `key` ，即 `char`
  * 初始化 `end` 标识
  * 清理存 `children` 节点的容器

* 移动构造函数
  * 容器内容交换用到了容器的方法 `swap`

* 为当前节点插入给定 `key` 的子节点
  * 需要判定当前节点是否有这个 `key` 的子节点，以及给定子节点的 `key` 和子节点的 `key` 是否对应
  * 在子节点存储在子节点容器中使用了 `std::forward`（完美转发），**保持保证原始参数类型不变，可以避免在函数调用的时候发生不必要的拷贝和移动**


#### TrieNodeWithValue

* 继承自 `TrieNode` 类，与父类不同的是，这个节点是用来存储每个单词对应的 `value` 的，所以增加了成员变量 `Value_`
* 该节点使用的条件
  * 本身这个节点已经存在，但是不是一个字符串的结尾，插入的新字符串在这个节点结尾，需要替换节点
    * 移动构造函数（将 `TrieNode` 类型节点转换成 `TrieNodeWithValue` 类型），其中用到了完美转发，将传入的 **`TrieNode` 右值引用**转发给父类的移动构造函数
      * 函数体内需要修改 `value` 以及标记 `end` 节点（通过调用父类的方法）
  * 本身不存在这个节点，可以直接使用 `TrieNodeWithValue` 来作为子节点
    * 构造函数，实际不适用，在后续的 Trie 树插入代码中，使用了TrieNode类的

#### Trie

* 为了使 Trie 树可以作为 `26` 个字母为起始节点的存储树，需要将根节点设置为 `'\0'`，这样根节点可以指向 `26` 个字母
  * 涉及到独占指针更换指向的问题，使用 `reset` 方法

* Trie 树需要提供插入、删除和查找的操作
  * 插入操作
    * 遍历字符串，去查找 Trie 树中有没有 `char` 的节点，没有就创建，有就递归到下一个，一直找到最后一个位置的节点，但是不创建最后一个 `char` 对应的节点，或者不找到最后一个 `char` 对应的子节点（通过判断当前节点的下个一节点是否是字符串的结尾，如果是，就停止遍历，这时节点就停在了倒数第二个 `char` 上了），因为需要根据最后一个节点的类型去判定是创建新节点还是转换节点类型
    * 获取最后一个字符的节点，判断这个节点的状态
      * 首先判断无法插入的状态（即有这个节点，但是是 `end` 节点）
      * 然后在判断其他的情况
      * **注意：独占指针的 `get()` 方法是获取其中对象的指针**
      * **注意：只能操作指向独占指针的指针**
  * 删除操作
    * 链表类型的删除，可以通过差分节点记录来删除即（<前一节点，下一节点>这种节点入栈，从栈顶找到倒数第二个节点以此类推进行删除下一个节点）
    * 遍历字符串，在 `Trie` 树中找到所有节点，如果没找到就 `return`，遍历需要存储前一节点以及对应的下一个节点
    * 出栈删除节点，在获取节点的时候使用了 `std::get<0>(tuple)` 获取 `tuple` 的内容（提高代码可读性和可维护性）（不满足节点使用 `continue` 跳出当前循环继续向下找，满足条件删除，和压栈是否的方法相同，有子节点压栈 `continue`，不满足返回 `false`）
  * 查询操作
    * 查询操作和插入操作大致相似，但是不会去在字符串到结尾就跳出，因为要获取最后的节点
      * 涉及了一个指针的转换 `dynamic_cast`

#### 并发操作

* 只需要在 Trie 树的插入删除查询操作的增加读写锁来达到一致性的问题
  * 需要注意的是，只要有 `return` 就要在 `return` 之前解锁，防止死锁
  * 可以使用 `std::scoped_lock` 去解锁，使用这个之后需要自己声明 `mutex`，用来加共享锁



## project_1 - buffer_pool

### 实验目的

* 实现一个面向磁盘存储的缓存池，在数据库读取磁盘数据页的时候，将数据也存储到缓存池的帧中，用以下次访问。同时缓存池大小限制，还需要设计一个页的 **替换策略**（`LRU-K`），因为设计并发问题，所以要对数据的访问加锁
* 同时表对应的内存所在的帧需要进行记录，因此设计一个哈希表进行存储，考虑到可扩展性、负载均衡、高效的查询效率以及内存的利用率问题，采用 **可扩展哈希表**
  * 动态扩容：可扩展哈希表可以动态地扩大自己的大小，以适应数据的增长。在哈希表满载时，可扩展哈希表可以通过重新分配桶来扩容，避免了重新哈希的开销。
  * 均衡负载：可扩展哈希表可以将数据均匀地分布在多个桶中，避免了传统哈希表中出现某些桶过度拥挤的情况。这可以提高哈希表的性能和可扩展性。
  * 高效查询：可扩展哈希表可以在常数时间内进行查找、插入和删除操作，因为它使用哈希函数将数据映射到桶中，而哈希函数的计算量是固定的。
  * 内存利用率高：可扩展哈希表可以动态地分配内存，因此它可以更好地利用可用内存，以适应数据的大小变化。
* 缓存池的替换策略：`LRU-K`，在 `LRU` 的基础上维护了一个 最近访问 K 的序列，每次淘汰的时候，都从这个序列中最远的（最久未被访问）的开始淘汰。同时需要维护一个计数表，来记录帧访问的次数。**替换策略只涉及缓存池的帧**
  * 替换策略的本质是对缓存池的帧进行驱逐，`LRU-K` 的大小就是缓存池的大小


### 实验内容

* 根据缓存池的结构，需要实现三个部分
  * `ExtendibleHashTable` 用以存储磁盘与对应的帧的记录，可扩展哈希表需要实现桶与目录，以及基本的哈希表的插入、查找和删除操作。
  * `LRUKReplacer` 用以替换缓冲区帧中的数据，与 `LRU` 不同的是，这个策略为了避免之前频繁使用，而后继续使用的概率会降到很低的情况，去维护一个访问次数 `K` 的帧访问列表。用来替换访问 `K` 次后的长时间未被访问的帧
    * 实现一个驱逐的功能，驱逐 `K` 列表中最远的帧
    * 实现一个基本的记录功能，当帧被访问的时候进行计数
    * 实现一个手动设置可驱逐的功能
    * 删除帧
    * 当前 `size`，指的是当前有多少帧被使用
  * `BufferPoolManagerInstance` 用以管理缓存池的实例，初始化缓存池、可扩展哈希以及替换策略。每次访问的磁盘页数据不在缓存池的帧中，就需要将磁盘页从磁盘中读取出来，然后存储在帧中，同时标记帧被使用的次数，以及将磁盘页和帧的对应关系存储到可扩展哈希表中用来每次访问数据的判断是否在缓存池中。
    * 插入新页
    * 向缓存池获取页
    * 删除页
    * 解除页面的锁定
    * 刷脏
* 可以把缓存池理解成一个列表，帧对应每个列表的元素位置，缓存池尺寸表示列表的长度，缓存池会根据访问的磁盘也，将页从磁盘中读取出来存储到列表中，每次使用列表，会增加其使用次数。因为列表的长度有先，所以设置一个列表的内容的替换策略。

### 实验外内容

* `Page` 存储磁盘页的数据结构，在这里了解存储磁盘页的基本数据结构。该类用来存储磁盘页的数据，同时标记磁盘页的 `id`，脏页标记，锁定标记。
  * 磁盘页 `id`：因为是存储磁盘页数据的，所以需要标记磁盘页的 `id`
  * 锁定计数：每次使用都需要将锁定计数增加，锁定计数存在时不能从缓存池驱逐该页
  * 脏页标记：由于缓存池为了减少 I/O 操作不会立刻将修改后的页更新到磁盘中，所以要使用脏页来标记未刷新的页。
  * 由于并发操作，所以提供了页的读写锁

### 实验要点

#### ExtendibleHashTable

* 可扩展哈希表的基本属性：
  * 桶：用来装数据，桶的大小固定，根据桶的深度来标记桶有没有进行分裂，同时桶拥有查找、插入、删除操作
  * 目录：寻找对应桶的目录，就是一个列表，根据下表来寻找桶，每次目录扩容相当于复制一遍目录对应的桶到新增加的目录中（原始目录和新增加的目录是对称关系），然后修改需要扩容的桶的指向即可
  * 全局深度与局部深度：全局深度是用来获取哈希值对应的目录索引的，同时也是判断需不需要扩容的指标
    * 目录扩容：溢出时，全局深度 == 局部深度，说明桶的数量已经达到上限了，即目录对应的桶的数量（每个桶在经过扩容的时候会多出一个相同指向的桶）。目录扩容时，不扩容的桶指向仍旧相同，这里就通道了局部深度。局部深度在扩容后会 `+1` 表示当前桶已经增加过一次。因此目录扩容后，相当于复制了一边前面的桶，为扩容的桶，扩容目录不修改指向。
    * 桶扩容：找要扩容的桶，可以根据局部深度来去找，因为局部深度可以表示当前桶的获取目录下表的掩码（通过掩码获取目录）。与局部深度的二进制位对应的高一位，是新桶与旧桶相区分的位（每次桶扩容，当前桶会被复制一份，即高一位区分），通过与这一个标志位相与的结果来确定将新数据插入哪个桶。
* 目录对应的下表的获取：通过全局深度来进行计算（与操作）
* 可扩展哈希表的操作
  * 查找：通过提供的获取索引的 `func` 来获取 `key` 对应的桶的下标，然后调用桶的 `find` 函数去查找，将找到的 `value` 进行返回。
  * 插入：插入操作较为复杂，需要根据桶是否满进行扩容，同时还需判断扩容后是否还是满的
    * 通过对当前的 `key` 不断获取索引同时判断对应的桶是否已满，来解决扩容后还是满的情况，此部分代码之解决扩容，不解决存入，因为需要根据桶内是否有相同元素来执行更新
      * 判断目录扩容：如果全局深度与局部深度相同，就需要对目录进行扩容，目录扩容即目录 `resize` 后根据之前的容量进行复制
      * 桶扩容：创建新桶，同时获取 `mask` （需要扩容桶的局部深度），用以将原本桶的数据重分配到新的桶时区分桶
      * 扩容桶数据的重分配
      * 新桶的重链接
    * 获取桶，同时判断桶中是否有相同元素，有则更新，无则调用桶的插入函数
  * 删除：与查找操作相同，调用桶的删除操作
* 可扩展哈希表的桶的操作
  * 桶内存储元素是使用 `list`
  * 查找：用以将查找到的 `value` 返回
  * 插入：会判断桶是否满
  * 删除：需要找到 `key` 对应的地址，然后删除（使用 `std::find_if`）

#### LRUKReplacer

* 替换策略的基本属性：
  * 维护一个访问到达 `K` 次的列表和一个历史访问列表
  * 因为需要记录次数，所以需要增加一个记录帧访问次数的无序哈希表
  * 因为需要快速访问历史列表，历史列表不存在访问后就放到队头，所以历史队列中的帧记录的时候为了加速访问，就需要一个记录帧以及帧对应历史队列位置的无序哈希表，用以加速访问
  * `K` 次的列表（缓存队列）同样需要一个无序哈希表来查找存放帧的位置
  * 因为是驱逐策略，所以需要一个记录帧是否可驱逐的记录表（无序哈希表）
* 基本的功能
  * 驱逐功能（先驱逐历史队列中的帧，在驱逐缓存中的帧），反向遍历历史列表，将最远的可驱逐的帧进行驱逐，同时初始化相应的记录，缓存列表同，如果驱逐一个就返回
  * 加入帧（放入历史队列还是放入缓存队列），通过判断访问记录是否等于 `K` 来确定插入到什么位置
    * 如果次数到达 `K` 次，则从历史队列中删除，放入缓存队列中
    * 大于 `K` 次，修改缓存队列，再缓存队列中就移到对头，在的话需要删除原本的然后移入队头
    * 如果没到 `K` 次，就插入到历史队列中
  * 设置可驱逐（设置可驱逐，不代表移入缓存，当前大小是根据可驱逐的个数来决定的），需要判定多种情况，因为需要修改 `LRU-K` 的大小
    * 如果本来就没有这个帧，就不需要操作
    * 如果本身是可驱逐的，但是设置了不可驱逐，当前大小要减少
    * 如果本身是不可驱逐的，但是当前设置了可驱逐，当前大小要增加
    * 最后才去设置可驱逐标志位
  * 移除固定的帧（不可移除非法帧，不可移除不可驱逐的帧），判断帧所在的位置（历史队列和缓存池）进行删除，初始化相关变量。
* `LRU-K` 的当前大小，表示可驱逐的帧的个数，如果驱逐或者删除，都会修改这个值，这个值就是让 `buffer_pool` 来判断有没有能驱逐的帧

#### BufferPoolManagerInstance

* 缓存池管理的基本属性：
  * 首先是可扩展哈希表的初始化变量
    * 桶的大小
  * 替换策略的初始化变量
    * `K` 值	
    * `LRU-K` 的大小
  * 未使用的帧的列表，从中取出帧的下标用来访问缓存池的帧
  * 缓存池的帧列表：`Page` 类，里面存放了磁盘页的内容以及一些相关的变量
* 基本功能
  * 增删查，获取 `pin` 是必要条件，只有未固定的帧才能够加入新的页
  * 插入新的磁盘页（需要从磁盘获取）
    * 需要先查看缓存池中的帧是否有未被 `Pin`，如果没有说明所有的帧都不能被驱逐
    * 如果存在空闲的，就去空闲查找可用帧，没有空闲的，就去 `lru-k` 中去驱逐一个帧，获取该帧的 `id` ，随后需要刷脏（因为内存中被驱逐，如果是脏页需要写回磁盘，保证数据库一致性）。最后要将记录该帧中该页的记录删除（可扩展哈希表记录页对应的帧）
    * 最后是插入阶段
      * 可扩展哈希表插入记录
      * `lru-k` 插入记录，同时设置不可驱逐
      * 帧中更新该页的属性
  * 获取页（相当于查找）
    * 要先判断页是否在内存中，在直接读取，不在需要从磁盘中读取，放入缓存池中
      * 从磁盘读取需要判断是否有未 `pin` 的，以及 `lru-k` 中是否有可驱逐的帧
  * 刷脏（缓存池必要的操作，除了单页刷脏还是整体刷脏）：整体刷脏直接遍历缓存池的帧列表
  * 删除页（相当于删除），将所有存在页的地方都进行删除（可扩展哈希表记录的页帧关系，`lru-k` 中，同时在空闲列表加入改帧），删除后对帧进行初始化



## project_2 - B+Tree

### 实验目的

* 实现一个存储记录的 `B+ tree` 结构，该结构由叶子节点和中间节点构成，由于中间的节点在实现中与叶子节点类似（使用记录的键值对列表存储）所以 **不存在指向叶子节点的指针**，而是使用 `key`，指向节点的 `page_id` 的形式来记录和查找子节点。只有叶子节点才记录了 **键值对**
  * 中间节点：`B+ tree` 的基本操作函数，设置 `kv`、插入记录、删除记录、以及 B+tree 的节点调整操作
  * 叶子节点：存储着所有的记录，同时是链式的形式，所有的节点以链表形式链接（通过记录下一个叶节点的page），与中间节点不同的是，需要有确定下一个叶节点的函数来设置当前页节点的下一个节点。

* 由于 `B+tree` 叶子节点之间是使用链表形式进行连接的，为了访问叶子节点，就需要实现一个叶节点记录的迭代器，同来进行叶节点记录的链式访问。
* 索引的并发：为了提高索引的访问效率，进行细粒度锁（蟹式锁），先对父节点加锁，子节点满足加锁条件则释放所有上层的锁，用来提高并发的效率。

### 实验内容

* 中间节点需要实现的部分：
  * 节点分裂，节点合并，节点删除
    * 节点分裂：插入节点后，因为左右子节点无法为其分担增加的节点，因此需要进行节点分裂，即创建一个新的节点，然后将当前节点的记录分流到新节点
    * 节点合并：删除节点的时候，因为不满足节点的最小值，同时左右节点无法向当前节点借用一个记录（左右节点的记录个数均等于最小值），因此需要与左右节点合并
    * 节点删除：如果删除的父节点的记录，但是记录只有一个，就要删除节点。
  * 移动记录，因为插入、删除所涉及的以上节点操作，都需要移动记录
    * 移动单个记录（向左右节点借记录，向左右节点分流记录）
    * 移动全部记录：用来合并节点时，将节点记录前部移动到相邻节点中
    * 移动一半记录：当分裂节点时，需要移动一半节点到新节点中
  * 记录的查找、插入、删除
* 叶节点需要实现的部分：
  * 与中间节点相似，不同点在于需要增加一个链接下一叶节点的变量（`next_page_id`）
* 叶节点的迭代器：基本的迭代器操作
  * 重载操作符：*，++，==，！=
  * 维护一个 `index`，用来查找每个节点的记录，每当跳入下一个节点，该值需要重置
  * 其中叶子节点是通过 `Page` 类中的 `data_` 进行指针类型转换获取的
* `b+tree` 类，通过叶子类中间节点类以及叶节点的迭代器构成一个完整的 `b+tree` 结构
* 

### 实验外内容

* `Transaction` 类，维护了一个事务所应该包括的内容：当前事务获取的各种锁的集合，事务的 `id`，以及前一事务的日志序列号，用以记录日志以及回滚操作

### 实验要点

* 插入节点后超过最大值，删除节点不满足最小值的调整策略（这些操作都是在 `B+tree` 中完整的，叶子节点只提供了移动记录的方法）：
  * 插入节点：
    * 向左右节点移动记录，如果左右节点没有满的话。中间节点的第一个叶子节点，只能向右节点进行移动记录。向左移动记录：将第一个节点移动到左节点的最后一个节点，同时修改父节点指向当前节点的记录。向右移动记录：将最后一个节点移动到右节点的第一个记录，同时修改父节点指向右节点的记录。
    * 如果无法移动则 **分裂节点**，文中使用了插入新节点

#### BPlusTreeLeafPage

* 设置下一个叶节点 ID 的函数：叶子节点本身要记录 **下一个叶子节点** 的页 ID，所以需要增加设置叶节点和获取下一个叶节点 ID 的方法，同时这两个方法在 **分裂节点** 时也会用到，用来对新节点指向进行更改
* 移动一半记录的函数：在分裂节点时候用来将一半的记录移动到新节点中
* 复制记录的函数，用来将给的记录列表的记录复制当前叶节点
* 获取 `key` 对应的 `index` 的函数：根据给定的 `key`，找到第一个大于等于他的位置（迭代器），然后根据两个迭代器的距离计算出两个迭代器之间间隔的元素个数，等同于找到大于等于他的位置，然后返回前一个位置的`index`（`distance` 函数）
* 插入函数：直接插入（先通过获取索引的函数获取插入位置的索引），不需要判断叶节点个数（原因是父节点会根据插入后的个数判断是否需要分裂）。`B+tree` 在此实现的规则时不可以有相同元素（唯一索引），所以需要先使用给定的比较函数判断是否相等才能插入
* 复制记录的函数：
  * 复制指定个数：用于移动一半记录的函数使用
  * 复制最后记录的函数：用来移动给定节点的最后一个元素到当前几点
  * 复制第一个节点的记录：用来将给定的记录（后一节点的第一个记录）复制到当前节点的最后一个记录
* 叶节点移动元素的操作（节点满了的情况）：
  * 移动一半记录：用来进行节点分裂
  * 移动第一个记录：用来插入节点的时候向左节点分流记录
  * 移动最后一个记录：用来插入节点的时候向右节点分裂记录

#### BPlusTreeInternalPage

* 基本的节点记录设置与叶子节点相似
* 插入与叶子节点不同，因为中间节点是插入的是 `key` 对应的子节点的页 ID，插入的函数是向 **旧记录** 之后插入一个新的记录（原因：中间节点的插入只出现在插入叶节点的时候分裂节点的时候，插入节点的时候会先查找叶子节点中能插入的相应位置，如果插入满了，移动记录或分裂节点，分裂节点的时候会产生新的节点，新的叶节点的位置就需要插入父节点中（新节点会是后半部分值，这个实现在 bplustree 中的 InsertIntoLeaf 中））
* 根节点分裂，当递归向上插入节点的时候，根节点满了的情况，需要产生一个新节点，将原本的根节点分裂成两个节点，然后插入到新的根节点中。
* 对节点数据进行操作（节点分裂，记录移动）的时候，与叶子节点不同（需要修改子节点中父节点的指向），因为中间节点的记录存储的是 <`key`，叶子节点对应的 `page_id`> 所以在操作的时候需要从缓存池拉取页（每条记录都是对应子节点的页，要修改子节点页对应的父节点，所以需要将子节点根据页 ID 从缓存池中拉取出来，修改其父节点的指向，帧的 data_ 存储了子节点）

#### BPlusTree

* `BPlusTree` 类是通过使用叶子节点类和中间节点类构建组织 `B+tree`
* 树的基本操作（插入、删除，查找）（加锁，锁队列在 txn 中）：
  * 空树需要创建新节点，插入叶节点（插入叶节点的函数）
    * 创建新节点的函数通过在缓存池中拉取帧（page_id）进行创建，同时初始化叶子节点
    * 插入叶节点的函数，通过获取叶节点的帧，然后将记录插入其中，采用的策略是直接插入，然后判断节点记录个数，根据新旧记录个数来进行操作
      * 个数相等则插入失败
      * 个数小于最大个数，直接插入
      * 个数大于等于最大数，进行节点分裂（先切分，然后转换叶子节点的下一节点指向，然后使用插入父节点的函数，将节点的 key 和 对应叶节点的 page_id 插入到父节点中）
    * 叶节点切分通过创建新的叶节点，然后移动记录来创建，函数返回新节点
    * 插入父节点的函数，需要判断旧节点的类型，所以需要将旧节点传入到函数中，根据节点类型进行不同的操作（其中传入的是当前节点，而不是父节点，该函数通过当前节点找到父节点）
      * 如果旧节点是根节点，那插入父节点就需要创建新节点
      * 同时和叶子节点相同，如果当前节点插入之后也满了，那么也需要在递归到父节点进行分裂
      * 因为插入的节点的类型以及插入的方式不同，插入父节点使用的创建新的节点指针（new char[]），然后将指针类型进行转化成父节点，同时将原父节点的数据复制进去。在对这个节点进行切分。然后操作完在将新生成的复制回去（来回复制的原因：因为中间节点存储的不是页，而且指向，所以需要对页内的数据进行修改，但是获取的数据是缓存池中的帧，不能直接对帧操作，需要对帧内的数据进行操作）
  * 删除操作，不进行删除，直接删除记录，然后使用数据重分类或整合函数，对该节点进行操作，满足条件不进行操作，不满足条件（小于最小的记录，检查是使用整合函数，还是重分配函数）
    * 数据重分配或整合函数，用来对删除记录后的节点进行操作的
      * 如果操作的是是根节点，同时有一个孩子节点，需要将孩子节点转换成新的根节点，如果没有孩子节点，同时根节点记录数为 0 了，就需要将树置为无效树
      * 如果删除后不满足最小值，需要进行调整
        * 在判断位置后，需要根据左右节点记录的数量判断是整合（相邻节点记录合并）还是重分配（借用一个记录）
        * 如果当前节点在父节点的最左边，就不能向左节点借用记录（在判断最左边的节点是 idx == 0 的同时，还需要满足不是最右面的记录，如果同时满足当前节点就只有一个节点了，这种情况是不能进行删除的，无法向左右节点合并或借用记录）
        * 如果当前节点在父节点的其他位置，向后面的节点借用
    * 数据合并，将两个叶节点的记录进行合并，因为数据合并涉及到了删除节点，所以需要递归的在对父节点进行判断重分配或整合
    * 数据重分配，借用相邻叶节点的记录来使当前节点满足最小值
  * 
