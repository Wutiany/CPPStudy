### 1.垃圾回收

程序在内存上被分为堆区、栈区、全局数据区、代码段、数据区五个部分

垃圾是指程序向堆栈申请的内存空间，随着程序的运行已经不再使用这些内存空间，这时如果不释放他们就会造成垃圾也就是内存泄漏

#### （1）标记清楚法

​			step1、进行 STW（stop the worl 即暂停程序业务逻辑），然后从 main 函数开始找到不可达的内存占用和可达的内存占用

​			step2、开始标记，程序找出可达内存占用并做标记

​			step3、结束 STW 停止暂停，让程序继续运行，循环该过程直到 main 生命周期结束

​			step4、清除未标记的内存占用

#### （2）三色标记法

​			三色标记算法将程序中的对象分成白色、黑色和灰色三类。

​			**白色**对象表示暂无对象引用的潜在垃圾，其内存可能会被垃圾收集器回收；

​			**灰色**对象表示活跃的对象，是黑色到白色的中间状态，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象；

​			**黑色**对象表示活跃的对象，包括不存在引用外部指针的对象以及从根对象可达的对象

​			step1、将所有对象标记为白色

​			step2、从根节点集合出发，将第一次遍历到的节点标记为灰色放入集合列表中

​			step3、遍历灰色集合，将灰色节点遍历到的白色节点标记为灰色，并把灰色节点标记为黑色

​			step4、循环这个过程

​			step5、直到灰色节点集合为空，回收所有的白色节点

​	问题：如果黑色节点引用了白色节点，而白色节点又和之前的灰色节点不可达，会导致白色节点被回收引起错误。

​    解决：

​			1.1强三色不变式：不允许黑色对象引用白色对象（插入屏障）

​					插入屏障：对象被引用时触发的机制，当白色对象被黑色对象引用时，白色对象被标记为灰色（栈上对象无插入屏障）。

​					缺点在于：如果对黑色节点在栈上新创建了一个对象 ，由于栈没有屏障机制，所以新的对象仍为白色节点会被回收

​			1.2弱三色不变式：黑色对象可以引用白色，白色对象存在其他灰色对象对他的引用，或者他的链路上存在灰色对象（删除屏障）

​					删除屏障：对象被删除时触发的机制。如果灰色对象引用的白色对象被删除时，那么白色对象会被标记为灰色。

​					缺点：这种做法回收精度较低，一个对象即使被删除仍可以活过这一轮再下一轮被回收

#### （3）混合写屏障

​			基于插入写屏障和删除写屏障在结束时需要 STW 来重新扫描栈，所带来的性能瓶颈，Go 在 1.8 引入了混合写屏障的方式实现了弱			三色不变式的设计方式，混合写屏障分下面四步

​			step1、GC 开始时将栈上可达对象全部标记为黑色（不需要二次扫描，无需 STW）

​			step2、GC 期间，任何栈上创建的新对象均为黑色

​			step3、被删除引用的对象标记为灰色

​			step4、被添加引用的对象标记为灰色

![图片](https://cdn.learnku.com/uploads/images/202107/14/81958/ouj5mdq4EQ.webp!large)

#### （4）GC触发条件

​			触发 GC 有俩个条件，

一是堆内存分配达到控制器计算的触发堆大小，之后堆内存达到上一次垃圾收集的 2 倍时才会触发 GC。

二是如果一定时间内没有触发，就会触发新的循环，该触发条件由 runtime.forcegcperiod 变量控默认为 2 分钟。

#### （5）TCMalloc算法

​		https://cloud.tencent.com/developer/article/1608933

​		是 Google 开发的内存分配器。Go语言内存管理的核心算法。

### 2.GMP调度

https://zhuanlan.zhihu.com/p/323271088

![img](https://pic1.zhimg.com/80/v2-a66cb6d05fb61e74681410feb3bd1df4_720w.webp)

​		G：goroutine，go的协程，每个go关键字都会创建一个协程

​		M：machine，工作线程，在Go中称为Machine，数量对应真实的CPU数。M运行G，G执行之后，M会从P获取下一个G，不断重复				下去。runtime/debug中的SetMaxThreads函数，设置M的最大数量
​		P：process，包含运行Go代码所需要的必要资源，用来**调度G和M之间的关联关系**，其数量可以通过GOMAXPROCS0来设置，默认		为核心数



1. **全局队列**（Global Queue）：存放等待运行的G。
2. **P的本地队列**：同全局队列类似，存放的也是等待运行的G，存的数量有限，不超过256个。新建G'时，G'优先加入到P的本地队列，如果队列满了，则会把本地队列中一半的G移动到全局队列。
3. **P列表**：所有的P都在程序启动时创建，并保存在数组中，最多有`GOMAXPROCS`(可配置)个。
4. **M**：线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列**拿**一批G放到P的本地队列，或从其他P的本地队列**偷**一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去。

**Goroutine调度器和操作系统调度器是通过M结合起来的，每个M都代表了1个内核线程，操作系统调度器负责把内核线程分配到CPU的核上执行**





#### 有关P和M的个数问题

M与P的数量没有绝对关系，一个M阻塞，P就会去创建或者切换另一个M，所以，即使P的默认数量是1，也有可能会创建很多个M出来。

1、P的数量：

- 由启动时环境变量`$GOMAXPROCS`或者是由`runtime`的方法`GOMAXPROCS()`决定。这意味着在程序执行的任意时刻都只有`$GOMAXPROCS`个goroutine在同时运行。

2、M的数量:

- go语言本身的限制：go程序启动时，会设置M的最大数量，默认10000.但是内核很难支持这么多的线程数，所以这个限制可以忽略。
- runtime/debug中的SetMaxThreads函数，设置M的最大数量
- 一个M阻塞了，会创建新的M。





#### P和M何时会被创建

1、P何时创建：在确定了P的最大数量n后，运行时系统会根据这个数量创建n个P。

2、M何时创建：没有足够的M来关联P并运行其中的可运行的G。比如所有的M此时都阻塞住了，而P中还有很多就绪任务，就会去寻找空闲的M，而没有空闲的，就会去创建新的M

### 3.go func() 调度流程

​			step1、我们通过 go func()来创建一个goroutine；

​			step2、有两个存储G的队列，一个是局部调度器P的本地队列、一个是全局G队列。新创建的G会先保存在P的本地队列中，如果P的本地队列已经满了就会保存在全局的队列中；

​			step3、G只能运行在M中，一个M必须持有一个P。M会从P的本地队列获取可执行的G，如果P的本地队列为空，就会想其他P的本地队列获取可执行的G来执行；

​			step4、一个M调度G执行的过程是一个循环机制；

​			step5、当M执行某一个G时候如果发生了阻塞，runtime会把这个线程M从P中摘除，然后再创建一个新的线程(如果有空闲的线程可用就复用空闲线程)来服务于这个P；

​			step6、当M调用结束时候，这个G会尝试获取一个空闲的P执行，并放入到这个P的本地队列。如果获取不到P，那么这个线程			M变成休眠状态， 加入到空闲线程中，然后这个G会被放入全局队列中

### 4.Goroutine调度策略

​			Step1.队列轮转：P会周期性的将G调度到M中执行，执行一段时间后，保存上下文，将G放到队列尾部，然后从队列中再取出一个			G进行调度，P还会周期性的查看全局队列是否有G等待调度到M中执行

​			Step2.系统调用：当G0即将进入系统调用时，M0将释放P，进而某个空闲的M1获取P，继续执行P队列中剩下的G。M1的来源有			可能是M的缓存池，也可能是新建的。

​			Step3.当G0系统调用结束后，如果有空闲的P，则获取一个P，继续执行G0。如果没有，则将G0放入全局队列，等待被其他的P调			度。然后M0将进入缓存池睡眠

### 5.CSP模型-通信顺序进程

​			**通过通信来实现内存共享。**

​			是一种并发编程模型，是一个很强大的并发数据模型，是上个世纪七十年代提出的，用于描述两个独立的并发实体通过共享的通讯 			channel(管道)进行通信的并发模型。它不关注发送消息的实体，而关注与发送消息时使用的channel。

​			Goroutine 和 Channel 分别对应 CSP 中的实体和传递信息的媒介，Goroutine 之间会通过 Channel 传递数据。

### 6.进程、线程、协程

​			进程：是进行资源分配的基本单位，每个进程都有自己的独立内存空间，由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大

​			线程：线程又叫做轻量级进程，是进程的一个实体，是**任务调度的基本单位**位，与同属一个进程的其他的线程共享进程所拥有的全部资源。

​			协程：**协程是一种用户态的轻量级线程。\**协程的调度完全由用户控制，\*\*协程拥有自己的寄存器上下文和栈\*\*。协程调度切换时，将寄存器上下文和栈保存，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有\**内核切换的开销**，可以不加锁的访问全局变量，所以上下文的切换非常快。。



​			1.一个线程可以有多个协程
​			2.线程、进程都是同步机制，而协程是异步
​			3.**协程可以保留上一次调用时的状态**，当过程重入时，相当于进入了上一次的调用状态
​			4.协程是需要线程来承载运行的，所以协程并不能取代线程，「线程是被分割的CPU资源，协程是组织好的代码流程」

### 7.进程间通信方式---IPC

​			每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内			核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机			制称为进程间通信（IPC，InterProcess Communication）

### 8.通道---channel

​			不要通过共享内存的方式进行通信，而是应该通过通信的方式共享内存

​			多个Goroutine能够独立运行并不存在直接关联，但是能通过 Channel 间接完成通信。

​			（1）先入先出

​					先从 Channel 读取数据的 Goroutine 会先接收到数据；

​					先向 Channel 发送数据的 Goroutine 会得到先发送数据的权利；

​					带缓冲区：

​					发送方会向缓冲区中写入数据，然后唤醒接收方，多个接收方会尝试从缓冲区中读取数据，如果没有读取到会重新陷入休眠；

​					接收方会从缓冲区中读取数据，然后唤醒发送方，发送方会尝试向缓冲区写入数据，如果缓冲区已满会重新陷入休眠；

​			（2）数据结构

​					[`runtime.hchan`](https://draveness.me/golang/tree/runtime.hchan) 结构体中的五个字段 `qcount`、`dataqsiz`、`buf`、`sendx`、`recv` 构建底层的循环队列

​					`qcount` — Channel 中的元素个数；

​					`dataqsiz` — Channel 中的循环队列的长度；

​					`buf` — Channel 的缓冲区数据指针；

​					`sendx` — Channel 的发送操作处理到的位置；

​					`recvx` — Channel 的接收操作处理到的位置；

### 9.context结构原理

​			Context（上下文）是Golang应用开发常用的并发控制技术 ，它可以控制一组呈树状结构的goroutine，每个goroutine拥有相同			的上下文。Context 是并发安全的，主要是用于控制多个协程之间的协作、取消操作。

​			（1）最大作用：在不同 Goroutine 之间对信号进行同步避免对计算资源的浪费，与此同时 Context 还能携带以请求为作用域的键											值对信息。

​			（2）参数：

​						**Deadline** — 返回 context.Context 被取消的时间，也就是完成工作的截止日期；
​						**Done** — 返回一个 Channel，这个 Channel 会在当前工作完成或者上下文被取消之后关闭，多次调用 Done 方法会返回同			一个Channel；
​						**Err** — 返回 context.Context 结束的原因，它只会在 Done 返回的 Channel 被关闭时才会返回非空的值；如果 				  			context.Context 被取消，会返回 Canceled 错误；如果 context.Context 超时，会返回 DeadlineExceeded 错误；
​						**Value** — 从 context.Context 中获取键对应的值，对于同一个上下文来说，多次调用 Value 并传入相同的 Key 会返回相同			的结果，该方法可以用来传递请求特定的数据；



### 10.context是并发安全的吗

valueCtx继承父Context，这种是采用匿名接口的继承实现方式，key,val用来存储携带的键值对。

添加键值对不是在原context结构体上直接添加，而是以此context作为父节点，重新创建一个新的valueCtx子节点，将键值对添加在子节点上，由此形成一条context链。

获取键值过程也是层层向上调用直到最终的根节点，中间要是找到了key就会返回，否会就会找到最终的emptyCtx返回nil

总结：context添加的键值对一个链式的，会不断衍生新的context，所以context本身是不可变的，因此是线程安全的。



### 11.new和make的区别

1.make 仅用来分配及初始化类型为 slice、map、chan 的数据。
2.new 可分配任意类型的数据，根据传入的类型申请一块内存，返回的是指针，即类型 *Type。需要实例化，否则空指针。
3.make 返回引用，即 Type，new 分配的空间被清零， make 分配空间后，会进行初始化。



### 12.Go中对nil的Slice和空Slice的处理是一致的吗?

首先Go的JSON 标准库对 nil slice 和 空 slice 的处理是不一致。
1.slice := make([]int,0）：slice不为nil，但是slice没有值，slice的底层的空间是空的。
2.slice := []int{} ：slice的值是nil，可用于需要返回slice的函数，当函数出现异常的时候，保证函数依然会有nil的返回



### 13.Golang的内存模型中为什么小对象多了会造成GC压力？

通常小对象过多会导致GC三色法消耗过多的GPU。优化思路是，减少对象分配。



### 14.channel为什么能做到线程安全？

channel可以理解是一个先进先出的循环队列，通过管道进行通信,发送一个数据到Channel和从Channel接收一个数据都是原子性的。源码中有乐观锁，不通过共享内存来通信，而是通过通信来共享内存，前者就是传统的加锁，后者就是Channel。设计Channel的主要目的就是在多任务间传递数据的，本身就是安全的。

### 15.Channel是同步的还是异步的？

Channel是异步进行的, channel存在3种状态：

1.nil，未初始化的状态，只进行了声明，或者手动赋值为nil
2.active，正常的channel，可读或者可写
3.closed，已关闭，千万不要误认为关闭channel后，channel的值是nil



### 16.Go的Struct能不能比较

1.相同struct类型的可以比较
2.不同struct类型的不可以比较,编译都不过，类型不匹配



### 17.Go的Slice如何扩容

1.首先判断，如果新申请容量（cap）大于2倍的旧容量（old.cap），最终容量（newcap）就是新申请的容量（cap）。
2.否则判断，如果旧切片的长度小于1024，则最终容量(newcap)就是旧容量(old.cap)的两倍。
3.否则判断，如果旧切片长度大于等于1024，则最终容量（newcap）从旧容量（old.cap）开始循环增加原来的1.25倍。
4.如果最终容量（cap）计算值溢出，则最终容量（cap）就是新申请容量（cap）。



### 18.在Go函数中为什么会发生内存泄露？发生了泄漏如何检测？

Goroutine 需要维护执行用户代码的上下文信息，在运行过程中需要消耗一定的内存来保存这类信息，如果一个程序持续不断地产生新的 goroutine，且不结束已经创建的 goroutine 并复用这部分内存，就会造成内存泄漏的现象。
可以通过Go自带的工具pprof或者使用Gops去检测诊断当前在系统上运行的Go进程的占用的资源。

### 19.Go中两个Nil可能不相等吗？

~~~go
func main() {
  var p *int =nil
  var i interface{} = p
  print(i == p) // true
  print(p == nil) //true
  print(i == nil) // false
  
}
~~~



### 20.Go语言中的内存对齐

CPU 并不会以一个一个字节去读取和写入内存。相反 CPU 读取内存是一块一块读取的，块的大小可以为 2、4、6、8、16 字节等大小。块大小我们称其为内存访问粒度，内存访问粒度跟机器字长有关。

对齐规则：
1.结构体的成员变量，第一个成员变量的偏移量为 0。往后的每个成员变量的对齐值必须为**编译器默认对齐长度**或当前**成员变量类型的长度**，取**最小值**作为当前类型的对齐值。其偏移量必须为对齐值的整数倍
2.结构体本身，对齐值必须为编译器默认对齐长度，或结构体的**所有成员变量**类型中的**最大长度**，取最大数的最小整数倍作为对齐值
3.结合以上两点，可得知若编译器默认对齐长度，超过结构体内成员变量的类型最大长度时，默认对齐长度是没有任何意义的

### 21.两个 interface 可以比较吗？

1.判断类型是否一样
reflect.TypeOf(a).Kind() == reflect.TypeOf(b).Kind()

2.判断两个interface{}是否相等
reflect.DeepEqual(a, b interface{})

3.将一个interface{}赋值给另一个interface{}
reflect.ValueOf(a).Elem().Set(reflect.ValueOf(b))



### 21.什么是 rune 类型？

Go语言的字符有以下两种：

1.uint8 类型，或者叫 byte 型，代表了 ASCII 码的一个字符。
2.rune 类型，代表一个 UTF-8 字符，当需要处理中文、日文或者其他复合字符时，则需要用到 rune 类型。rune 类型等价于 int32 类型。



### 22.空 struct{} 占用空间么？用途是什么？

空结构体 struct{} 实例不占据任何的内存空间。

用途：
1.将 map 作为集合(Set)使用时，可以将值类型定义为空结构体，仅作为占位符使用即可。
2.不发送数据的信道(channel)
使用 channel 不需要发送任何的数据，只用来通知子协程(goroutine)执行任务，或只用来控制协程并发度。
3.结构体只包含方法，不包含任何的字段



### 23.互斥锁、读写锁、死锁

互斥锁：防止两条[线程](https://zh.wikipedia.org/wiki/线程)同时对同一公共资源（比如[全域变数](https://zh.wikipedia.org/wiki/全域變數)）进行读写的机制。该目的通过将代码切片成一个一个的[临界区域](https://zh.wikipedia.org/wiki/临界区域)（critical section）达成。临界区域指的是一块对公共资源进行存取的代码，并非一种机制或是算法

读写锁：通常有些公共数据修改的机会很少，但其读的机会很多。并且在读的过程中会伴随着查找，给这种代码加锁会降低我们的程序效率。读写锁可以解决这个问题。

- 死锁

两个事务对竞争同一共享资源时产生的互相等待的现象，且这种现象在无外力干扰情况下不能停止，就是死锁

死锁产生的四个必要条件:

1. 互斥条件：一个资源每次只能被一个进程使用

2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

3. 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。

4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。

   a. 预防死锁

   可以把资源一次性分配：（破坏请求和保持条件）

   然后剥夺资源：即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）

   资源有序分配法：要约定好访问顺序，不能线程 T1 先访问表 A 后访问表 B，线程T2 先访问 表B 后访问 表A, 这个情况极容易死锁。

   采用分布式锁或者使用乐观锁



### 24.Data Race问题怎么解决？能不能不加锁解决这个问题？

竞争检测器已经完全集成到Go工具链中，仅仅添加-race标志到命令行就使用了检测器。

要想解决数据竞争的问题可以使用互斥锁sync.Mutex,解决数据竞争(Data race),也可以使用管道解决,使用管道的效率要比互斥锁高.



### 25.负载均衡原理是什么?

负载均衡Load Balance）是高可用网络基础架构的关键组件，通常用于将工作负载分布到多个服务器来提高网站、应用、数据库或其他服务的性能和可靠性。负载均衡，其核心就是网络流量分发，分很多维度。

负载均衡（Load Balance）通常是分摊到多个操作单元上进行执行，例如Web服务器、FTP服务器、企业关键应用服务器和其它关键任务服务器等，从而共同完成工作任务。

负载均衡是建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。

通过一个例子详细介绍:

- 没有负载均衡 web 架构

[![img](https://github.com/KeKe-Li/golang-interview-questions/raw/master/src/images/66.jpg)](https://github.com/KeKe-Li/golang-interview-questions/blob/master/src/images/66.jpg)

在这里用户是直连到 web 服务器，如果这个服务器宕机了，那么用户自然也就没办法访问了。 另外，如果同时有很多用户试图访问服务器，超过了其能处理的极限，就会出现加载速度缓慢或根本无法连接的情况。

而通过在后端引入一个负载均衡器和至少一个额外的 web 服务器，可以缓解这个故障。 通常情况下，所有的后端服务器会保证提供相同的内容，以便用户无论哪个服务器响应，都能收到一致的内容。

- 有负载均衡 web 架构

[![img](https://github.com/KeKe-Li/golang-interview-questions/raw/master/src/images/67.jpg)](https://github.com/KeKe-Li/golang-interview-questions/blob/master/src/images/67.jpg)

用户访问负载均衡器，再由负载均衡器将请求转发给后端服务器。在这种情况下，单点故障现在转移到负载均衡器上了。 这里又可以通过引入第二个负载均衡器来缓解。

那么负载均衡器的工作方式是什么样的呢,负载均衡器又可以处理什么样的请求？

负载均衡器的管理员能主要为下面四种主要类型的请求设置转发规则：

- HTTP (七层)
- HTTPS (七层)
- TCP (四层)
- UDP (四层)

负载均衡器如何选择要转发的后端服务器？

负载均衡器一般根据两个因素来决定要将请求转发到哪个服务器。首先，确保所选择的服务器能够对请求做出响应，然后根据预先配置的规则从健康服务器池（healthy pool）中进行选择。

因为，负载均衡器应当只选择能正常做出响应的后端服务器，因此就需要有一种判断后端服务器是否健康的方法。为了监视后台服务器的运行状况，运行状态检查服务会定期尝试使用转发规则定义的协议和端口去连接后端服务器。 如果，服务器无法通过健康检查，就会从池中剔除，保证流量不会被转发到该服务器，直到其再次通过健康检查为止。

负载均衡算法

负载均衡算法决定了后端的哪些健康服务器会被选中。 其中常用的算法包括：

- Round Robin（轮询）：为第一个请求选择列表中的第一个服务器，然后按顺序向下移动列表直到结尾，然后循环。
- Least Connections（最小连接）：优先选择连接数最少的服务器，在普遍会话较长的情况下推荐使用。
- Source：根据请求源的 IP 的散列（hash）来选择要转发的服务器。这种方式可以一定程度上保证特定用户能连接到相同的服务器。

如果你的应用需要处理状态而要求用户能连接到和之前相同的服务器。可以通过 Source 算法基于客户端的 IP 信息创建关联，或者使用粘性会话（sticky sessions）。

除此之外，想要解决负载均衡器的单点故障问题，可以将第二个负载均衡器连接到第一个上，从而形成一个集群



### 26.微服务架构是什么样子的?

通常传统的项目体积庞大，需求、设计、开发、测试、部署流程固定。新功能需要在原项目上做修改。

但是微服务可以看做是对大项目的拆分，是在快速迭代更新上线的需求下产生的。新的功能模块会发布成新的服务组件，与其他已发布的服务组件一同协作。 服务内部有多个生产者和消费者，通常以http rest的方式调用，服务总体以一个（或几个）服务的形式呈现给客户使用。

微服务架构是一种思想对微服务架构我们没有一个明确的定义，但简单来说微服务架构是：

采用一组服务的方式来构建一个应用，服务独立部署在不同的进程中，不同服务通过一些轻量级交互机制来通信，例如 RPC、HTTP 等，服务可独立扩展伸缩，每个服务定义了明确的边界，不同的服务甚至可以采用不同的编程语言来实现，由独立的团队来维护。

Golang的微服务框架[kit](https://gokit.io/)中有详细的微服务的例子,可以参考学习.

微服务架构设计包括：

1. 服务熔断降级限流机制 熔断降级的概念(Rate Limiter 限流器,Circuit breaker 断路器).
2. 框架调用方式解耦方式 Kit 或 Istio 或 Micro 服务发现(consul zookeeper kubeneters etcd ) RPC调用框架.
3. 链路监控,zipkin和prometheus.
4. 多级缓存.
5. 网关 (kong gateway).
6. Docker部署管理 Kubenetters.
7. 自动集成部署 CI/CD 实践.
8. 自动扩容机制规则.
9. 压测 优化.
10. Logging 日志.



### 27.Epoll原理.

Epoll是一种IO多路复用技术，可以非常高效的处理数以百万计的Socket句柄，比起以前的Select和Poll效率提高了很多。

先简单了解下如何使用C库封装的3个epoll系统调用。

```
int epoll_create(int size);  
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);  
int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);  
```



从调用方式就可以看到epoll相比select/poll的优越之处是,因为后者每次调用时都要传递你所要监控的所有socket给select/poll系统调用，这意味着需要将用户态的socket列表copy到内核态，如果以万计的句柄会导致每次都要copy几十几百KB的内存到内核态，非常低效。而我们调用`epoll_wait`时就相当于以往调用select/poll，但是这时却不用传递socket句柄给内核，因为内核已经在epoll_ctl中拿到了要监控的句柄列表。

所以，实际上在你调用`epoll_create`后，内核就已经在内核态开始准备帮你存储要监控的句柄了，每次调用`epoll_ctl`只是在往内核的数据结构里塞入新的socket句柄。

在内核里，一切皆文件。所以，epoll向内核注册了一个文件系统，用于存储上述的被监控socket。当你调用epoll_create时，就会在这个虚拟的epoll文件系统里创建一个file结点。这个file只服务于epoll。

epoll在被内核初始化时（操作系统启动），同时会开辟出epoll自己的内核高速缓冲区，用于安置每一个我们想监控的socket，这些socket会以**红黑树**的形式保存在内核cache里，以支持快速的查找、插入、删除。这个内核高速cache区，就是建立连续的物理内存页，然后在之上建立slab层，通常来讲，就是物理上分配好你想要的size的内存对象，每次使用时都是使用空闲的已分配好的对象。



epoll的高效就在于，当我们调用`epoll_ctl`往里塞入百万个句柄时，`epoll_wait`仍然可以飞快的返回，并有效的将发生事件的句柄给我们用户。这是由于我们在调用`epoll_create`时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。

而且，通常情况下即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait仅需要从内核态copy少量的句柄到用户态而已，因此就会非常的高效！

如此，一个红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。执行`epoll_create`时，创建了红黑树和就绪链表，执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据。执行epoll_wait时立刻返回准备就绪链表里的数据即可。

最后看看epoll独有的两种模式LT和ET。无论是LT和ET模式，都适用于以上所说的流程。区别是，LT模式下，只要一个句柄上的事件一次没有处理完，会在以后调用epoll_wait时每次返回这个句柄，而ET模式仅在第一次返回。

当一个socket句柄上有事件时，内核会把该句柄插入准备就绪的list链表，这时我们调用`epoll_wait`，会把准备就绪的socket拷贝到用户态内存，然后清空准备就绪list链表，最后，`epoll_wait`需要做的事情，就是检查这些socket，如果不是ET模式（就是LT模式的句柄了），并且这些socket上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表了。所以，非ET的句柄，只要它上面还有事件，epoll_wait每次都会返回。而ET模式的句柄，除非有新中断到，即使socket上的事件没有处理完，也是不会每次从epoll_wait返回的。

因此epoll比select的提高实际上是一个用空间换时间思想的具体应用.对比阻塞IO的处理模型, 可以看到采用了多路复用IO之后, 程序可以自由的进行自己除了IO操作之外的工作, 只有到IO状态发生变化的时候由多路复用IO进行通知, 然后再采取相应的操作, 而不用一直阻塞等待IO状态发生变化,提高效率.



### 28.go内存分配

核心思想就是把内存分为多级管理+复用。



* 内存管理组件

内存分配由内存分配器完成。分配器由3种组件构成：`mcache`, `mcentral`, `mheap`。

* mcache

每个工作线程都会绑定一个mcache，本地缓存可用的`mspan`资源，这样就可以直接给Goroutine分配，因为不存在多个Goroutine竞争的情况，所以不会消耗锁资源。

* mcentral

为所有`mcache`提供切分好的`mspan`资源。每个`central`保存一哥全局`mspan`列表，包括已分配出去的和未分配出去的。 每个`mcentral`对应一种`mspan`。当工作线程的`mcache`中没有合适（也就是特定大小的）的`mspan`时就会从`mcentral`获取。

`mcentral`被所有的工作线程共同享有，存在多个Goroutine竞争的情况，因此会消耗锁资源

* mheap

`mheap`：代表Go程序持有的所有堆空间，Go程序使用一个`mheap`的全局对象`_mheap`来管理堆内存。

当`mcentral`没有空闲的`mspan`时，会向`mheap`申请。而`mheap`没有资源时，会向操作系统申请新内存。`mheap`主要用于大对象的内存分配，以及管理未切割的`mspan`，用于给`mcentral`切割成小对象。



Go的内存分配器在分配对象时，根据对象的大小，分成三类：小对象（小于等于16B）、一般对象（大于16B，小于等于32KB）、大对象（大于32KB）。

大体上的分配流程：

- 32KB 的对象，直接从mheap上分配；
- <=16B 的对象使用mcache的tiny分配器分配；
- (16B,32KB] 的对象，首先计算对象的规格大小，然后使用mcache中相应规格大小的mspan分配；
- 如果mcache没有相应规格大小的mspan，则向mcentral申请
- 如果mcentral没有相应规格大小的mspan，则向mheap申请
- 如果mheap中也没有合适大小的mspan，则向操作系统申请

总结：

- Go在程序启动时，会向操作系统申请一大块内存，之后自行管理。
- Go内存管理的基本单元是mspan，它由若干个页组成，每种mspan可以分配特定大小的object。
- mcache, mcentral, mheap是Go内存管理的三大组件，层层递进。mcache管理线程在本地缓存的mspan；mcentral管理全局的mspan，供所有线程使用；mheap管理Go的所有动态分配内存。
- 极小对象会分配在一个object中，以节省资源，使用tiny分配器分配内存；一般小对象通过mspan分配内存；大对象则直接由mheap分配内存。



### 29.知道golang的**内存逃逸**吗？什么情况下会发生内存逃逸？

`golang程序变量`会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在`栈上`分配。否则就说它 `逃逸` 了，必须在`堆上分配`。

能引起变量逃逸到堆上的**典型情况**：

- **在方法内把局部变量指针返回** 局部变量原本应该在栈中分配，在栈中回收。但是由于返回时被外部引用，因此其生命周期大于栈，则溢出。
- **发送指针或带有指针的值到 channel 中。** 在编译时，是没有办法知道哪个 goroutine 会在 channel 上接收数据。所以编译器没法知道变量什么时候才会被释放。
- **在一个切片上存储指针或带指针的值。** 一个典型的例子就是 []*string 。这会导致切片的内容逃逸。尽管其后面的数组可能是在栈上分配的，但其引用的值一定是在堆上。
- **slice 的背后数组被重新分配了，因为 append 时可能会超出其容量( cap )。** slice 初始化的地方在编译时是可以知道的，它最开始会在栈上分配。如果切片背后的存储要基于运行时的数据进行扩充，就会在堆上分配。
- **在 interface 类型上调用方法。** 在 interface 类型上调用方法都是动态调度的 —— 方法的真正实现只能在运行时知道。想像一个 io.Reader 类型的变量 r , 调用 r.Read(b) 会使得 r 的值和切片b 的背后存储都逃逸掉，所以会在堆上分配

- 通过一个例子加深理解，接下来尝试下怎么通过 `go build -gcflags=-m` 查看逃逸的情况。

















