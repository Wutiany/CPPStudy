### 一、三范式

第一范式：每个列都不可以再拆分。

第二范式：在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分。

第三范式：在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键。

在设计数据库结构的时候，要尽量遵守三范式，如果不遵守，必须有足够的理由。比如性能。事实上我们经常会为了性能而妥协数据库的设计

### 二、MySQL的binlog有有几种录入格式？分别有什么区别？

有三种格式，statement，row和mixed。

**statement**模式下，**每一条会修改数据的sql都会记录在binlog中**。**不需要记录每一行的变化，减少了binlog日志量，节约了IO，提高性能**。由于sql的执行是有上下文的，因此在保存的时候需要保存相关的信息，同时还有一些使用了函数之类的语句无法被记录复制。
**row**级别下，不记录sql语句上下文相关信息，仅保存哪条记录被修改。记**录单元为每一行的改动，基本是可以全部记下来但是由于很多操作，会导致大量行的改动(比如alter table)**，因此这种模式的文件保存的信息太多，日志量太大。
**mixed**一种折中的方案，普通操作使用statement记录，当无法使用statement的时候使用row。
此外，新版的MySQL中对row级别也做了一些优化，**当表结构发生变化的时候，会记录语句而不是逐行记录**。

### 三、MySQL存储引擎MyISAM与InnoDB区别

![image-20230207171820769](/Users/zhaojiawei/Library/Application Support/typora-user-images/image-20230207171820769.png)



### 四、事物的四大特性(ACID)介绍一下?

原子性： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
一致性： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
隔离性： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
持久性： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。



### 五、什么是脏读？幻读？不可重复读？

**脏读**(Drity Read)：某个事务已更新一份数据，另一个事务在此时读取了同一份数据，由于某些原因，前一个RollBack了操作，则后一个事务所读取的数据就会是不正确的。
**不可重复读**(Non-repeatable read):在一个事务的两次查询之中数据不一致，这可能是两次查询过程中间插入了一个事务更新的原有的数据。
**幻读**(Phantom Read):在一个事务的两次查询中数据笔数不一致，例如有一个事务查询了几列(Row)数据，而另一个事务却在此时插入了新的几列数据，先前的事务在接下来的查询中，就会发现有几列数据是它先前所没有的。



### 六、什么是事务的隔离级别？MySQL的默认隔离级别是什么？

READ-UNCOMMITTED(**读未提交**)： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
READ-COMMITTED(**读已提交**)： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
REPEATABLE-READ(**可重复读**)： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
SERIALIZABLE(**可串行化**)： 最高的隔离级别，完全服从ACID的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。

Mysql 默认采用的可重复读隔离级别



### 七、索引的数据结构

https://www.modb.pro/db/78756

Hash：不适合范围查询--因为哈希表的所有 key 都会经过哈希函数计算，然后再存放数据，本来可能有序的 key，但经过哈希函数计算出来的值就不是有序的了，所以这个时候，如果要在哈希表中进行范围查找，就只能对整个哈希表进行遍历了，只有符合条件范围的数据，才取出来。当我们数据库中的数据越来越多，达到几百万甚至几千万条的时候，这个时候，对整个表的遍历是非常耗时的

二叉树：无论是二叉搜索树，还是 AVL 树，亦或是红黑树，它们都是二叉树的一种，特点都是每个结点最多只有两个子结点，如果存储大量数据的话，那么树的高度会非常高。而 MySQL 存储的数据最终是要落地到磁盘的，MySQL 应用程序读取数据时，需要将数据从磁盘先加载到内存后才能继续操作，所以这中间会发生磁盘 IO，而如果树太高，每遍历一层结点时，就需要从磁盘读取一次数据，也就是发生一次 IO，如果数据在树高为 20 的地方，那查找一次数据就得发生 20 次 IO，这对应用程序简直就是灾难性的，耗时太长了。因此二叉树在 MySQL 这种需要存储大量数据的场景下，是不适合当做索引的数据结构的，因为树太高，操作数据时会发生多次磁盘 IO，性能太差。

B树和B+树：让树的每个结点尽可能多的拥有多个子结点，也就是多叉树，那这样在大量储存数据时，树高就低很多了。

B-Tree 的特点是无论叶子结点和非叶子结点，它都存有索引值和数据；

B+Tree 的特点是只有叶子结点才会存放索引值和数据，非叶子结点只会存放索引值本身。

因此对于非叶子结点，一个结点中，B+Tree 存放的索引值数量会远远大于 B-Tree（因为一个结点的空间是有限的，B-Tree 要存放索引+数据，而 B+Tree 只需要存放索引），这样就导致了每个结点中，B+Tree 能向下分出更多的叉，子结点数更多。



### 			八、死锁

死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。

死锁产生的四个必要条件:

1. 互斥条件：一个资源每次只能被一个进程使用

2. 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。

3. 不剥夺条件:进程已获得的资源，在末使用完之前，不能强行剥夺。

4. 循环等待条件:若干进程之间形成一种头尾相接的循环等待资源关系。 这四个条件是死锁的必要条件，只要系统发生死锁，这些条件必然成立，而只要上述条件之一不满足，就不会发生死锁。

   a. 预防死锁

   可以把资源一次性分配：（破坏请求和保持条件）

   然后剥夺资源：即当某进程新的资源未满足时，释放已占有的资源（破坏不可剥夺条件）

   资源有序分配法：要约定好访问顺序，不能线程 T1 先访问表 A 后访问表 B，线程T2 先访问 表B 后访问 表A, 这个情况极容易死锁。

   采用分布式锁或者使用乐观锁

解决：

1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。

2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；

3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁粒度，通过表级锁定来减少死锁产生的概率；

如果业务处理不好可以用分布式事务锁或者使用乐观锁	

### 九、CAS理论

流程：

![图片](https://s2.51cto.com/oss/202207/29/168f1cb70591c0d7ef6314df45bee46fbad743.jpg)

缺点：

（1）循环时间长开销大：在Unsafe的实现中使用了自旋锁。在该环节如果CAS操作失败，就需要循环进行CAS操作(do while循环同时将期望值更新为最新的)，如果长时间都不成功的话，那么会造成CPU极大的开销。

（2）只能保证一个共享变量的原子操作：如果存在多个共享变量，或一整个代码块的逻辑需要保证线程安全，CAS就无法保证原子性操作了，此时就需要考虑采用加锁方式（悲观锁）保证原子性，或者有一个取巧的办法，把多个共享变量合并成一个共享变量进行CAS操作。

（3）ABA问题：

- 进程P1在共享变量中读到值为A；
- P1被抢占了，进程P2执行；
- P2把共享变量里的值从A改成了B，再改回到A，此时被P1抢占；
- P1回来看到共享变量里的值没有被改变，于是继续执行；

ABA问题的解决思路就是使用版本号：在变量前面追加上版本号，每次变量更新的时候把版本号加1，那么A->B->A就会变成1A->2B->3A。



### 十、行级锁、表级锁、页级锁

行级锁 行级锁是Mysql中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁 和 排他锁。

特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

表级锁 表级锁是MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MYISAM与INNODB都支持表级锁定。表级锁定分为表共享读锁（共享锁）与表独占写锁（排他锁）。

特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。

页级锁 页级锁是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。

特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般



### 十一、主从复制

（1）主库接收SQL请求记录到自己的 binlog 中
 （2）从库的 I/O thread 去请求主库的 binlog
 （3）主库的 I/O dump thread 给备库 I/O thread传送 binlog
 （4）从库将得到的 binlog 写到自己的 relay log 中

（5）从库的 SQL thread 读取 relay log 执行 SQL



### 十二、两阶段提交

![image-20230208171425507](/Users/zhaojiawei/Library/Application Support/typora-user-images/image-20230208171425507.png)

![img](https://pic1.zhimg.com/80/v2-fd517a8d56ef67dad9f8d384d1a23fd4_720w.webp)

### 十三、创建索引时需要注意什么？

**非空字段**：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；
取值离散大的字段：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；
**索引字段越小越好**：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高



### 十四、百万级别或以上的数据如何删除

关于索引：由于索引需要额外的维护成本，因为索引文件是单独存在的文件,所以当我们对数据的增加,修改,删除,都会产生额外的对索引文件的操作,这些操作需要消耗额外的IO,会降低增/改/删的执行效率。所以，在我们删除数据库百万级别数据的时候，查询MySQL官方手册得知删除数据的速度和创建的索引数量是成正比的。

所以我们想要删除百万数据的时候可以

1、先删除索引（此时大概耗时三分多钟）
2、然后删除其中无用数据（此过程需要不到两分钟）
3、删除完成后重新创建索引(此时数据较少了)创建索引也非常快，约十分钟左右。

### 十五、什么是最左前缀原则？什么是最左匹配原则

顾名思义，就是最左优先，在创建多列索引时，要根据业务需求，where子句中使用最频繁的一列放在最左边。
最左前缀匹配原则，非常重要的原则，mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a = 1 and b = 2 and c > 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。
=和in可以乱序，比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式



### 十六、乐观锁和悲观锁

- 乐观锁：乐观锁在操作数据时非常乐观，认为别人不会同时修改数据。因此乐观锁不会上锁，只是在执行更新的时候判断一下在此期间别人是否修改了数据：如果别人修改了数据则放弃操作，否则执行操作。CAS机制和版本号机制
- 悲观锁：悲观锁在操作数据时比较悲观，认为别人会同时修改数据。因此操作数据时直接把数据锁住，直到操作完成后才会释放锁；上锁期间其他人不能修改数据。悲观锁的实现方式是加锁，加锁既可以是对代码块加锁，也可以是对数据加锁（如MySQL中的排它锁）

CAS只能保证单个变量操作的原子性，当涉及到多个变量时，CAS是无能为力的，而synchronized则可以通过对整个代码块加锁来处理。再比如版本号机制，如果query的时候是针对表1，而update的时候是针对表2，也很难通过简单的版本号来实现乐观锁。



- 当竞争不激烈 (出现并发冲突的概率小)时，乐观锁更有优势，因为悲观锁会锁住代码块或数据，其他线程无法同时访问，影响并发，而且加锁和释放锁都需要消耗额外的资源。
- 当竞争激烈(出现并发冲突的概率大)时，悲观锁更有优势，因为乐观锁在执行更新时频繁失败，需要不断重试，浪费CPU资源





### 十七、乐观锁加锁吗？

（1）乐观锁本身是不加锁的，只是在更新时判断一下数据是否被其他线程更新了；AtomicInteger便是一个例子。

（2）有时乐观锁可能与加锁操作合作



十八、sql优化

**system级别**>const级别>eq_ref界别>ref>range>index>all

1、违反最左前缀法则

2、索引范围条件右边的列---where 条件后 先查= 再查>,<,!=

3、尽量使用覆盖索引----减少select*

4、mysql在使用不等于（!=、<>）的时候无法使用索引会导致全表扫描（除覆盖索引外）

5、like以通配符开头（'%abc'）----用全文索引解决，match()

6、字符串不加单引号索引失效

7、or连接

8、order by 主键   ----force index，FId+0
