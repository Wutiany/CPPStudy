# 2022fall_实验笔记

## project_0 - trie tree

### 实验目的

* 实现一个存储字符串的 `trie` 树，同一个单词的同一个位置如果字母相同，使用同一个 `node`，最终的节点存储字符串键对应的 `value`，用来判断。

### 实验内容

* 根据数据结构需要实现三个部分：
  * `TrieNode` 类：trie 树的每个基本的节点
  * `TrieNodeWithValue` 类：`TrieNode` 的子类，用于表示每个单词结尾字母的 `kv` 结构
  * `Trie` 类：用于组织节点，并不同于存储任何 `kv`，增删改查。注意不允许插入重复的键。
  * 并发操作：通过加入 lock 实现 `trie` 树的并发

### 实现要点

#### TrieNode

* 类的初始化
  * 初始化节点存储的 `key` ，即 `char`
  * 初始化 `end` 标识
  * 清理存 `children` 节点的容器

* 移动构造函数
  * 容器内容交换用到了容器的方法 `swap`

* 为当前节点插入给定 `key` 的子节点
  * 需要判定当前节点是否有这个 `key` 的子节点，以及给定子节点的 `key` 和子节点的 `key` 是否对应
  * 在子节点存储在子节点容器中使用了 `std::forward`（完美转发），**保持保证原始参数类型不变，可以避免在函数调用的时候发生不必要的拷贝和移动**


#### TrieNodeWithValue

* 继承自 `TrieNode` 类，与父类不同的是，这个节点是用来存储每个单词对应的 `value` 的，所以增加了成员变量 `Value_`
* 该节点使用的条件
  * 本身这个节点已经存在，但是不是一个字符串的结尾，插入的新字符串在这个节点结尾，需要替换节点
    * 移动构造函数（将 `TrieNode` 类型节点转换成 `TrieNodeWithValue` 类型），其中用到了完美转发，将传入的 **`TrieNode` 右值引用**转发给父类的移动构造函数
      * 函数体内需要修改 `value` 以及标记 `end` 节点（通过调用父类的方法）
  * 本身不存在这个节点，可以直接使用 `TrieNodeWithValue` 来作为子节点
    * 构造函数，实际不适用，在后续的 Trie 树插入代码中，使用了TrieNode类的

#### Trie

* 为了使 Trie 树可以作为 `26` 个字母为起始节点的存储树，需要将根节点设置为 `'\0'`，这样根节点可以指向 `26` 个字母
  * 涉及到独占指针更换指向的问题，使用 `reset` 方法

* Trie 树需要提供插入、删除和查找的操作
  * 插入操作
    * 遍历字符串，去查找 Trie 树中有没有 `char` 的节点，没有就创建，有就递归到下一个，一直找到最后一个位置的节点，但是不创建最后一个 `char` 对应的节点，或者不找到最后一个 `char` 对应的子节点（通过判断当前节点的下个一节点是否是字符串的结尾，如果是，就停止遍历，这时节点就停在了倒数第二个 `char` 上了），因为需要根据最后一个节点的类型去判定是创建新节点还是转换节点类型
    * 获取最后一个字符的节点，判断这个节点的状态
      * 首先判断无法插入的状态（即有这个节点，但是是 `end` 节点）
      * 然后在判断其他的情况
      * **注意：独占指针的 `get()` 方法是获取其中对象的指针**
      * **注意：只能操作指向独占指针的指针**
  * 删除操作
    * 链表类型的删除，可以通过差分节点记录来删除即（<前一节点，下一节点>这种节点入栈，从栈顶找到倒数第二个节点以此类推进行删除下一个节点）
    * 遍历字符串，在 `Trie` 树中找到所有节点，如果没找到就 `return`，遍历需要存储前一节点以及对应的下一个节点
    * 出栈删除节点，在获取节点的时候使用了 `std::get<0>(tuple)` 获取 `tuple` 的内容（提高代码可读性和可维护性）（不满足节点使用 `continue` 跳出当前循环继续向下找，满足条件删除，和压栈是否的方法相同，有子节点压栈 `continue`，不满足返回 `false`）
  * 查询操作
    * 查询操作和插入操作大致相似，但是不会去在字符串到结尾就跳出，因为要获取最后的节点
      * 涉及了一个指针的转换 `dynamic_cast`

#### 并发操作

* 只需要在 Trie 树的插入删除查询操作的增加读写锁来达到一致性的问题
  * 需要注意的是，只要有 `return` 就要在 `return` 之前解锁，防止死锁
  * 可以使用 `std::scoped_lock` 去解锁，使用这个之后需要自己声明 `mutex`，用来加共享锁



## project_1 - buffer_pool

### 实验目的

* 实现一个面向磁盘存储的缓存池，在数据库读取磁盘数据页的时候，将数据也存储到缓存池的帧中，用以下次访问。同时缓存池大小限制，还需要设计一个页的 **替换策略**（`LRU-K`），因为设计并发问题，所以要对数据的访问加锁
* 同时表对应的内存所在的帧需要进行记录，因此设计一个哈希表进行存储，考虑到可扩展性、负载均衡、高效的查询效率以及内存的利用率问题，采用 **可扩展哈希表**
  * 动态扩容：可扩展哈希表可以动态地扩大自己的大小，以适应数据的增长。在哈希表满载时，可扩展哈希表可以通过重新分配桶来扩容，避免了重新哈希的开销。
  * 均衡负载：可扩展哈希表可以将数据均匀地分布在多个桶中，避免了传统哈希表中出现某些桶过度拥挤的情况。这可以提高哈希表的性能和可扩展性。
  * 高效查询：可扩展哈希表可以在常数时间内进行查找、插入和删除操作，因为它使用哈希函数将数据映射到桶中，而哈希函数的计算量是固定的。
  * 内存利用率高：可扩展哈希表可以动态地分配内存，因此它可以更好地利用可用内存，以适应数据的大小变化。
* 缓存池的替换策略：`LRU-K`，在 `LRU` 的基础上维护了一个 最近访问 K 的序列，每次淘汰的时候，都从这个序列中最远的（最久未被访问）的开始淘汰。同时需要维护一个计数表，来记录帧访问的次数。**替换策略只涉及缓存池的帧**
  * 替换策略的本质是对缓存池的帧进行驱逐，`LRU-K` 的大小就是缓存池的大小


### 实验内容

* 根据缓存池的结构，需要实现三个部分
  * `ExtendibleHashTable` 用以存储磁盘与对应的帧的记录，可扩展哈希表需要实现桶与目录，以及基本的哈希表的插入、查找和删除操作。
  * `LRUKReplacer` 用以替换缓冲区帧中的数据，与 `LRU` 不同的是，这个策略为了避免之前频繁使用，而后继续使用的概率会降到很低的情况，去维护一个访问次数 `K` 的帧访问列表。用来替换访问 `K` 次后的长时间未被访问的帧
    * 实现一个驱逐的功能，驱逐 `K` 列表中最远的帧
    * 实现一个基本的记录功能，当帧被访问的时候进行计数
    * 实现一个手动设置可驱逐的功能
    * 删除帧
    * 当前 `size`，指的是当前有多少帧被使用
  * `BufferPoolManagerInstance` 用以管理缓存池的实例，初始化缓存池、可扩展哈希以及替换策略。每次访问的磁盘页数据不在缓存池的帧中，就需要将磁盘页从磁盘中读取出来，然后存储在帧中，同时标记帧被使用的次数，以及将磁盘页和帧的对应关系存储到可扩展哈希表中用来每次访问数据的判断是否在缓存池中。
    * 插入新页
    * 向缓存池获取页
    * 删除页
    * 解除页面的锁定
    * 刷脏
* 可以把缓存池理解成一个列表，帧对应每个列表的元素位置，缓存池尺寸表示列表的长度，缓存池会根据访问的磁盘也，将页从磁盘中读取出来存储到列表中，每次使用列表，会增加其使用次数。因为列表的长度有先，所以设置一个列表的内容的替换策略。

### 实验外内容

* `Page` 存储磁盘页的数据结构，在这里了解存储磁盘页的基本数据结构。该类用来存储磁盘页的数据，同时标记磁盘页的 `id`，脏页标记，锁定标记。
  * 磁盘页 `id`：因为是存储磁盘页数据的，所以需要标记磁盘页的 `id`
  * 锁定计数：每次使用都需要将锁定计数增加，锁定计数存在时不能从缓存池驱逐该页
  * 脏页标记：由于缓存池为了减少 I/O 操作不会立刻将修改后的页更新到磁盘中，所以要使用脏页来标记未刷新的页。
  * 由于并发操作，所以提供了页的读写锁

### 实验要点

#### ExtendibleHashTable

* 可扩展哈希表的基本属性：
  * 桶：用来装数据，桶的大小固定，根据桶的深度来标记桶有没有进行分裂，同时桶拥有查找、插入、删除操作
  * 目录：寻找对应桶的目录，就是一个列表，根据下表来寻找桶，每次目录扩容相当于复制一遍目录对应的桶到新增加的目录中（原始目录和新增加的目录是对称关系），然后修改需要扩容的桶的指向即可
  * 全局深度与局部深度：全局深度是用来获取哈希值对应的目录索引的，同时也是判断需不需要扩容的指标
    * 目录扩容：溢出时，全局深度 == 局部深度，说明桶的数量已经达到上限了，即目录对应的桶的数量（每个桶在经过扩容的时候会多出一个相同指向的桶）。目录扩容时，不扩容的桶指向仍旧相同，这里就通道了局部深度。局部深度在扩容后会 `+1` 表示当前桶已经增加过一次。因此目录扩容后，相当于复制了一边前面的桶，为扩容的桶，扩容目录不修改指向。
    * 桶扩容：找要扩容的桶，可以根据局部深度来去找，因为局部深度可以表示当前桶的获取目录下表的掩码（通过掩码获取目录）。与局部深度的二进制位对应的高一位，是新桶与旧桶相区分的位（每次桶扩容，当前桶会被复制一份，即高一位区分），通过与这一个标志位相与的结果来确定将新数据插入哪个桶。
* 目录对应的下表的获取：通过全局深度来进行计算（与操作）
* 可扩展哈希表的操作
  * 查找：通过提供的获取索引的 `func` 来获取 `key` 对应的桶的下标，然后调用桶的 `find` 函数去查找，将找到的 `value` 进行返回。
  * 插入：插入操作较为复杂，需要根据桶是否满进行扩容，同时还需判断扩容后是否还是满的
    * 通过对当前的 `key` 不断获取索引同时判断对应的桶是否已满，来解决扩容后还是满的情况，此部分代码之解决扩容，不解决存入，因为需要根据桶内是否有相同元素来执行更新
      * 判断目录扩容：如果全局深度与局部深度相同，就需要对目录进行扩容，目录扩容即目录 `resize` 后根据之前的容量进行复制
      * 桶扩容：创建新桶，同时获取 `mask` （需要扩容桶的局部深度），用以将原本桶的数据重分配到新的桶时区分桶
      * 扩容桶数据的重分配
      * 新桶的重链接
    * 获取桶，同时判断桶中是否有相同元素，有则更新，无则调用桶的插入函数
  * 删除：与查找操作相同，调用桶的删除操作
* 可扩展哈希表的桶的操作
  * 桶内存储元素是使用 `list`
  * 查找：用以将查找到的 `value` 返回
  * 插入：会判断桶是否满
  * 删除：需要找到 `key` 对应的地址，然后删除（使用 `std::find_if`）

#### LRUKReplacer

* 替换策略的基本属性：
  * 维护一个访问到达 `K` 次的列表和一个历史访问列表
  * 因为需要记录次数，所以需要增加一个记录帧访问次数的无序哈希表
  * 因为需要快速访问历史列表，历史列表不存在访问后就放到队头，所以历史队列中的帧记录的时候为了加速访问，就需要一个记录帧以及帧对应历史队列位置的无序哈希表，用以加速访问
  * `K` 次的列表（缓存队列）同样需要一个无序哈希表来查找存放帧的位置
  * 因为是驱逐策略，所以需要一个记录帧是否可驱逐的记录表（无序哈希表）
* 基本的功能
  * 驱逐功能（先驱逐历史队列中的帧，在驱逐缓存中的帧），反向遍历历史列表，将最远的可驱逐的帧进行驱逐，同时初始化相应的记录，缓存列表同，如果驱逐一个就返回
  * 加入帧（放入历史队列还是放入缓存队列），通过判断访问记录是否等于 `K` 来确定插入到什么位置
    * 如果次数到达 `K` 次，则从历史队列中删除，放入缓存队列中
    * 大于 `K` 次，修改缓存队列，再缓存队列中就移到对头，在的话需要删除原本的然后移入队头
    * 如果没到 `K` 次，就插入到历史队列中
  * 设置可驱逐（设置可驱逐，不代表移入缓存，当前大小是根据可驱逐的个数来决定的），需要判定多种情况，因为需要修改 `LRU-K` 的大小
    * 如果本来就没有这个帧，就不需要操作
    * 如果本身是可驱逐的，但是设置了不可驱逐，当前大小要减少
    * 如果本身是不可驱逐的，但是当前设置了可驱逐，当前大小要增加
    * 最后才去设置可驱逐标志位
  * 移除固定的帧（不可移除非法帧，不可移除不可驱逐的帧），判断帧所在的位置（历史队列和缓存池）进行删除，初始化相关变量。
* `LRU-K` 的当前大小，表示可驱逐的帧的个数，如果驱逐或者删除，都会修改这个值，这个值就是让 `buffer_pool` 来判断有没有能驱逐的帧

#### BufferPoolManagerInstance

* 缓存池管理的基本属性：
  * 首先是可扩展哈希表的初始化变量
    * 桶的大小
  * 替换策略的初始化变量
    * `K` 值	
    * `LRU-K` 的大小
  * 未使用的帧的列表，从中取出帧的下标用来访问缓存池的帧
  * 缓存池的帧列表：`Page` 类，里面存放了磁盘页的内容以及一些相关的变量
* 基本功能
  * 增删查，获取 `pin` 是必要条件，只有未固定的帧才能够加入新的页
  * 插入新的磁盘页（需要从磁盘获取）
    * 需要先查看缓存池中的帧是否有未被 `Pin`，如果没有说明所有的帧都不能被驱逐
    * 如果存在空闲的，就去空闲查找可用帧，没有空闲的，就去 `lru-k` 中去驱逐一个帧，获取该帧的 `id` ，随后需要刷脏（因为内存中被驱逐，如果是脏页需要写回磁盘，保证数据库一致性）。最后要将记录该帧中该页的记录删除（可扩展哈希表记录页对应的帧）
    * 最后是插入阶段
      * 可扩展哈希表插入记录
      * `lru-k` 插入记录，同时设置不可驱逐
      * 帧中更新该页的属性
  * 获取页（相当于查找）
    * 要先判断页是否在内存中，在直接读取，不在需要从磁盘中读取，放入缓存池中
      * 从磁盘读取需要判断是否有未 `pin` 的，以及 `lru-k` 中是否有可驱逐的帧
  * 刷脏（缓存池必要的操作，除了单页刷脏还是整体刷脏）：整体刷脏直接遍历缓存池的帧列表
  * 删除页（相当于删除），将所有存在页的地方都进行删除（可扩展哈希表记录的页帧关系，`lru-k` 中，同时在空闲列表加入改帧），删除后对帧进行初始化



## project_2 - B+Tree

### 实验目的

* 实现一个存储记录的 `B+ tree` 结构，该结构由叶子节点和中间节点构成，由于中间的节点在实现中与叶子节点类似（使用记录的键值对列表存储）所以 **不存在指向叶子节点的指针**，而是使用 `key`，指向节点的 `page_id` 的形式来记录和查找子节点。只有叶子节点才记录了 **键值对**
  * 中间节点：`B+ tree` 的基本操作函数，设置 `kv`、插入记录、删除记录、以及 B+tree 的节点调整操作
  * 叶子节点：存储着所有的记录，同时是链式的形式，所有的节点以链表形式链接（通过记录下一个叶节点的page），与中间节点不同的是，需要有确定下一个叶节点的函数来设置当前页节点的下一个节点。

* 由于 `B+tree` 叶子节点之间是使用链表形式进行连接的，为了访问叶子节点，就需要实现一个叶节点记录的迭代器，同来进行叶节点记录的链式访问。
* 索引的并发：为了提高索引的访问效率，进行细粒度锁（蟹式锁），先对父节点加锁，子节点满足加锁条件则释放所有上层的锁，用来提高并发的效率。

### 实验内容

* 中间节点需要实现的部分：
  * 节点分裂，节点合并，节点删除
    * 节点分裂：插入节点后，因为左右子节点无法为其分担增加的节点，因此需要进行节点分裂，即创建一个新的节点，然后将当前节点的记录分流到新节点
    * 节点合并：删除节点的时候，因为不满足节点的最小值，同时左右节点无法向当前节点借用一个记录（左右节点的记录个数均等于最小值），因此需要与左右节点合并
    * 节点删除：如果删除的父节点的记录，但是记录只有一个，就要删除节点。
  * 移动记录，因为插入、删除所涉及的以上节点操作，都需要移动记录
    * 移动单个记录（向左右节点借记录，向左右节点分流记录）
    * 移动全部记录：用来合并节点时，将节点记录前部移动到相邻节点中
    * 移动一半记录：当分裂节点时，需要移动一半节点到新节点中
  * 记录的查找、插入、删除
* 叶节点需要实现的部分：
  * 与中间节点相似，不同点在于需要增加一个链接下一叶节点的变量（`next_page_id`）
* 叶节点的迭代器：基本的迭代器操作
  * 重载操作符：*，++，==，！=
  * 维护一个 `index`，用来查找每个节点的记录，每当跳入下一个节点，该值需要重置
  * 其中叶子节点是通过 `Page` 类中的 `data_` 进行指针类型转换获取的
* `b+tree` 类，通过叶子类中间节点类以及叶节点的迭代器构成一个完整的 `b+tree` 结构
* 

### 实验外内容

* `Transaction` 类，维护了一个事务所应该包括的内容：当前事务获取的各种锁的集合，事务的 `id`，以及前一事务的日志序列号，用以记录日志以及回滚操作

### 实验要点

* 插入节点后超过最大值，删除节点不满足最小值的调整策略（这些操作都是在 `B+tree` 中完整的，叶子节点只提供了移动记录的方法）：
  * 插入节点：
    * 向左右节点移动记录，如果左右节点没有满的话。中间节点的第一个叶子节点，只能向右节点进行移动记录。向左移动记录：将第一个节点移动到左节点的最后一个节点，同时修改父节点指向当前节点的记录。向右移动记录：将最后一个节点移动到右节点的第一个记录，同时修改父节点指向右节点的记录。
    * 如果无法移动则 **分裂节点**，文中使用了插入新节点

#### BPlusTreeLeafPage

* 设置下一个叶节点 ID 的函数：叶子节点本身要记录 **下一个叶子节点** 的页 ID，所以需要增加设置叶节点和获取下一个叶节点 ID 的方法，同时这两个方法在 **分裂节点** 时也会用到，用来对新节点指向进行更改
* 移动一半记录的函数：在分裂节点时候用来将一半的记录移动到新节点中
* 复制记录的函数，用来将给的记录列表的记录复制当前叶节点
* 获取 `key` 对应的 `index` 的函数：根据给定的 `key`，找到第一个大于等于他的位置（迭代器），然后根据两个迭代器的距离计算出两个迭代器之间间隔的元素个数，等同于找到大于等于他的位置，然后返回前一个位置的`index`（`distance` 函数）
* 插入函数：直接插入（先通过获取索引的函数获取插入位置的索引），不需要判断叶节点个数（原因是父节点会根据插入后的个数判断是否需要分裂）。`B+tree` 在此实现的规则时不可以有相同元素（唯一索引），所以需要先使用给定的比较函数判断是否相等才能插入
* 复制记录的函数：
  * 复制指定个数：用于移动一半记录的函数使用
  * 复制最后记录的函数：用来移动给定节点的最后一个元素到当前几点
  * 复制第一个节点的记录：用来将给定的记录（后一节点的第一个记录）复制到当前节点的最后一个记录
* 叶节点移动元素的操作（节点满了的情况）：
  * 移动一半记录：用来进行节点分裂
  * 移动第一个记录：用来插入节点的时候向左节点分流记录
  * 移动最后一个记录：用来插入节点的时候向右节点分裂记录

#### BPlusTreeInternalPage

* 基本的节点记录设置与叶子节点相似
* 插入与叶子节点不同，因为中间节点是插入的是 `key` 对应的子节点的页 ID，插入的函数是向 **旧记录** 之后插入一个新的记录（原因：中间节点的插入只出现在插入叶节点的时候分裂节点的时候，插入节点的时候会先查找叶子节点中能插入的相应位置，如果插入满了，移动记录或分裂节点，分裂节点的时候会产生新的节点，新的叶节点的位置就需要插入父节点中（新节点会是后半部分值，这个实现在 bplustree 中的 InsertIntoLeaf 中））
* 根节点分裂，当递归向上插入节点的时候，根节点满了的情况，需要产生一个新节点，将原本的根节点分裂成两个节点，然后插入到新的根节点中。
* 对节点数据进行操作（节点分裂，记录移动）的时候，与叶子节点不同（需要修改子节点中父节点的指向），因为中间节点的记录存储的是 <`key`，叶子节点对应的 `page_id`> 所以在操作的时候需要从缓存池拉取页（每条记录都是对应子节点的页，要修改子节点页对应的父节点，所以需要将子节点根据页 ID 从缓存池中拉取出来，修改其父节点的指向，帧的 data_ 存储了子节点）

#### BPlusTree

* `BPlusTree` 类是通过使用叶子节点类和中间节点类构建组织 `B+tree`
* 树的基本操作（插入、删除，查找）（加锁，锁队列在 txn 中）：
  * 空树需要创建新节点，插入叶节点（插入叶节点的函数）
    * 创建新节点的函数通过在缓存池中拉取帧（page_id）进行创建，同时初始化叶子节点
    * 插入叶节点的函数，通过获取叶节点的帧，然后将记录插入其中，采用的策略是直接插入，然后判断节点记录个数，根据新旧记录个数来进行操作
      * 个数相等则插入失败
      * 个数小于最大个数，直接插入
      * 个数大于等于最大数，进行节点分裂（先切分，然后转换叶子节点的下一节点指向，然后使用插入父节点的函数，将节点的 key 和 对应叶节点的 page_id 插入到父节点中）
    * 叶节点切分通过创建新的叶节点，然后移动记录来创建，函数返回新节点
    * 插入父节点的函数，需要判断旧节点的类型，所以需要将旧节点传入到函数中，根据节点类型进行不同的操作（其中传入的是当前节点，而不是父节点，该函数通过当前节点找到父节点）
      * 如果旧节点是根节点，那插入父节点就需要创建新节点
      * 同时和叶子节点相同，如果当前节点插入之后也满了，那么也需要在递归到父节点进行分裂
      * 因为插入的节点的类型以及插入的方式不同，插入父节点使用的创建新的节点指针（new char[]），然后将指针类型进行转化成父节点，同时将原父节点的数据复制进去。在对这个节点进行切分。然后操作完在将新生成的复制回去（来回复制的原因：因为中间节点存储的不是页，而且指向，所以需要对页内的数据进行修改，但是获取的数据是缓存池中的帧，不能直接对帧操作，需要对帧内的数据进行操作）
  * 删除操作，不进行删除，直接删除记录，然后使用数据重分类或整合函数，对该节点进行操作，满足条件不进行操作，不满足条件（小于最小的记录，检查是使用整合函数，还是重分配函数）
    * 数据重分配或整合函数，用来对删除记录后的节点进行操作的
      * 如果操作的是是根节点，同时有一个孩子节点，需要将孩子节点转换成新的根节点，如果没有孩子节点，同时根节点记录数为 0 了，就需要将树置为无效树
      * 如果删除后不满足最小值，需要进行调整
        * 在判断位置后，需要根据左右节点记录的数量判断是整合（相邻节点记录合并）还是重分配（借用一个记录）
        * 如果当前节点在父节点的最左边，就不能向左节点借用记录（在判断最左边的节点是 idx == 0 的同时，还需要满足不是最右面的记录，如果同时满足当前节点就只有一个节点了，这种情况是不能进行删除的，无法向左右节点合并或借用记录）
        * 如果当前节点在父节点的其他位置，向后面的节点借用
    * 数据合并，将两个叶节点的记录进行合并，因为数据合并涉及到了删除节点，所以需要递归的在对父节点进行判断重分配或整合（数据合并传入的节点是有先后顺序的）
    * 数据重分配，借用相邻叶节点的记录来使当前节点满足最小值
  * 叶子的迭代器函数
    * 无参数的 `begin` 找到第一个叶子节点
    * 有参数的 `begin` ，会找到对应的叶子，然后获取对应的索引，返回一个自定义的迭代器
    * `End` 获取最后一个节点之后的位置
  * 辅助函数（通过辅助函数进行树的操作）
    * 查找叶子节点（根据传入的操作，查找、插入、删除，进行锁升级，锁下放），读锁会自己锁定释放
    * 释放事务的锁队列中的锁，蟹式锁，锁底层，释放祖先的锁（写锁），读锁不需要释放，因为是共享锁，所以不影响其他事务并发读取。
    * 调整头页的根节点的记录

#### IndexIterator

* 叶子节点的索引，该类通过获取当前叶子节点，以及使用 `idx` 去以迭代器的形式访问叶子节点的记录，同时迭代式的访问下一个叶节点的记录（通过获取下一个叶子节点的 `page_id` 来进入下一个节点）



## project_3 - Query Execution

### 实验目的

* 实现基础的查询操作：顺序扫描、插入、删除、索引扫描，因为涉及数据的访问，所以需要加锁（根据事务的隔离级别）。初始化的时候都需要先获取表锁。
  * 顺序扫描：通过顺序扫描的计划节点获取满足表达式条件的结果
  * 插入：插入操作会有子执行器，因为插入不是直插入一个，每次插入的元组和对应的 `RID` 会通过子执行器获取。插入的同时需要更新索引
  * 删除：但是真正删除的时候是在事务提交的过程中，同时删除标记的时候会修改索引
  * 索引扫描：与顺序扫描不同的是，索引扫描需要创建 `B+Tree` 索引，初始化需要获取左表达式的值，通过获取的值，在索引中去搜索同时获取元组对应的 `rids`，具体的结果是通过表访问对应的 `rid` 来获取记录的值。（总体就是，索引扫描是利用将 `key` 转换成索引树，存储对应记录的 `rid`， 通过条件去获取索引树中对应的 `key` 的 `rid`）
* 实现基本的聚合和连接操作：聚合，循环嵌套连接，循环索引连接。
  * 聚合操作：和插入顺序扫描不同，聚合操作会提前根据聚合的类型将结果计算出，然后存储起来，通过访问存储的迭代器逐个发送聚合结果（某个属性的多个分组的聚合结果）
  * 循环嵌套连接：连接操作存在左右执行器（顺序扫描的执行器），用来获取左关系和右关系的结果。循环嵌套连接有两种操作（`inner join， left join`），这两个连接都是需要先获取右表的结果，然后将左表连接的右表的左边
    * `inner join`：只返回两个表共同的数据
    * `left join`：在 `inner join` 的基础上，还需要返回左表存在，但是右表不存在的数据，即右表的数据用 `NULL` 填充
    * 同时在一个函数中实现两个的话，需要对左表的每个记录去匹配右表，然后根据是否是左连接，去增加左表的空值匹配结果，因为遍历右表，但是火山模型每次只发送一个结果，所以需要一个记录右表遍历位置的索引标记，用来下次执行的时候继续遍历。
  * 循环索引连接：使用 B+Tree 索引来获取数据，与循环嵌套连接不同的是，通过索引只能获取记录所在的 磁盘位置，需要进行 `I/O` 操作获取数据，同时索引取代了右表获取记录的执行器。
  * 循环嵌套连接需要两个表达式，因为两个表达式都是根据条件进行筛选记录，但是循环索引只需要一个表达式，因为右表的表达式通过索引去代替了，每次会根据左表的一条记录的键来索引所有右表相关的记录的存储位置。所以当插入记录的时候就不能用执行器的方式获取右表列数了。
* 实现基本的排序、`limit` 和 `top-K` 以及优化。
  * 排序，在初始化的时候会直接进行排序，同时返回保存记录的列表
  * `limit`，通过维护一个计数值，调用子表达式获取结果。
  * `top-k`，通过将获取的记录进行比较，然后根据给定的排序类型，进行排序，只维护前n个，节省存储空间。
  * 将 `sort limit` 转换成 `topk` 的优化，重构计划节点




### 实验内容

* 基础查询操作：
  * 顺序扫描执行器，根据表达式，选择满足的结果
  * 插入执行器：根据插入执行器获取每个要插入的结果。然后插入表更新索引
  * 删除执行器：删除表中的记录同时更改索引，但是不立刻删除，提交后删除
  * 索引扫描执行器：通过索引来加速查找的速度
* 聚合连接操作：
  * 聚合执行器：根据聚合的 `key` 和具体聚合的类型，来获取值。
  * 循环嵌套连接执行器：通过两个子执行器进行循环嵌套连接
  * 循环索引连接执行器：通过将子执行器获取的结果替换成索引，来减少结果的存储以及访问的速度
* 排序、`limit` 和 `top-K` 以及优化：
  * 排序执行器：对子执行器获取的结果进行排序
  * `limit` 执行器：对子执行器获取的结果进行提取限制的记录个数
  * `top-K` 执行器：对结果排序，同时获取前 `K` 个结果
  * `sort_limit` 转换成 `top-K` 的优化器：将计划进行更改

### 实验外内容

* 记录的存储（`Tuple`， `Value`，`Schema`）
  * **Tuple**：存储数据，数据存储在一个 `char` 指针中，通过构造函数中初始化列表的 `new` 去分配一个 `char list`，用来存储具体的数据，通过位置偏移来获取数据，
  * **Value**：
  * **Schema**：

* 执行器上下文
* 存储聚集结果的哈希表

### 实验要点

**基础查询操作：顺序扫描执行器、插入执行器、删除执行器与索引扫描执行器**

#### SeqScanExecutor

* 基本操作：
  * 初始化操作：执行时锁表（读未提交不需要锁，因为隔离级别低，不考虑并发问题），同时获取表的迭代器，用来遍历表
  * 火山模型：
    * 每次向上层运算树发送一个记录，减少中间存储，流水线方式工作
    * 除读未提交状态外都上的共享锁（行锁），读取结束需要将事务的共享锁全部释放，以及释放表锁
    * 通过谓词过滤器选择符合条件的记录，如果找到了（根据谓词过滤器的 `Evaluate` 转换成 `bool` 类型，来表示是否满足条件），就跳出循环发送数据

#### InsertExecutor

* 基本操作：
  * 初始化操作：子执行器初始化。插入操作在初始化的时候需要先判断是否能获取意图排他锁，同时获取表的索引，因为插入的时候需要更新表的索引
  * 火山模型：
    * 插入操作通过子执行器（顺序扫描执行器获取要插入的每个记录），调用表的插入操作，插入后需要对记录进行锁定（可以避免脏读幻读），幻读一般发生在插入和删除操作，会加范围锁
    * 最后对索引树进行更新

#### DeleteExecutor

* 基本操作（与插入操作基本类似）：
  * 初始化操作：子执行器初始化。先获取表的意图排他锁，与插入操作相同
  * 火山模型：
    * 通过子执行器获取的记录与插入不同，删除会获得记录的 `rid`
    * 删除操作不会立刻删除，而是通过表进行标记删除的记录，等到提交的时候再删除

**基础的聚集和连接执行器：聚集执行器、嵌套循环连接与嵌套索引连接**

#### AggregationExecutor

* 基本操作：
  * 初始化操作：子执行器初始化（子执行器获取谓词的结果或者 `group by` 的结果），然后通过具体的聚集类型进行聚集计算，初始化会获取聚集的结果，如果是 `group by` 聚集结果会产生多个（`key` 对应 `value`）（通过运算树查看子执行器）。如果没有 key 对应的 value，但是需要计算的列属性又存在，则根据聚集类型创建一个初始化的结果
    * `count(*)` 采用 `0` 值初始化
    * 其他的采用 `NullValue` 初始化
  * 火山模型是发送计算后的结果

#### NestedLoopJoinExecutor

* 基本操作（`join` 操作是通过对 `Value` 的 `vector` 进行拼接左右属性的值）：
  * 初始化操作：左右表的执行器进行初始化，同时获取右表的数据，来为左表进行 `join`，因为 `Left Join` 是右表不存在的，用 `NULL` 来代替，所以去遍历右表
  * 火山模型：
    * 通过遍历右表，来匹配每个左表的记录，最后根据是否为左连接，来增加空值

#### NestIndexJoinExecutor

* 基本操作：
  * 初始化操作：初始化子执行器
  * 火山模型：
    * 左表通过子执行器获取，右表通过索引来获取，同时存储获取的记录的 `rids`（`b+tree` 索引的唯一性，一般只有一个记录）
    * 再根据左连接进行拼接 `NULL`

**基础的排序限制和 `Top-N` 优化：排序执行器、限制执行器、`Top-N` 执行器与 `Top-N` 优化**

#### SortExecutor

* 基本操作：
  * 初始化操作：初始化子执行器，同时将子执行器的所有结果获取，然后通过 `sort` 函数进行排序，如果按照多个列进行排序，就会有多个 `order by`。最后获取排序后的记录元组
  * 火山模型：
    * 每次发送一个元组的记录

#### LimitExecutor

* 基本操作：
  * 初始化操作：子执行器初始化，通过初始化获取记录的个数
  * 火山模型，每次获取子执行器的一个结果

#### TopNExecutor

* 基本操作：
  * 初始化操作：初始化子执行器，同时构建排序的 `lambda` 表达式，用以在优先级队列中对记录进行排序，将排序的结果放到元组中，用以火山模型进行返回
    * 排序顺序与实际是相反的（因为优先级队列是弹出堆顶的元素，保留堆低的元素，所以堆顶的元素就是 order by 中后面的数据）。如果是降序排序，获取的就是最大的 `N` 个，因此堆应该使用小堆顶的方式，弹出最小的。即堆的排序方式与需要结果的排序方式相反。
    * 堆的操作：传入的 `a`，是堆中的元素，传入的 `b` 是要插入堆中的元素，`a > b` 就可以理解成升序（**小堆顶**），如果 `a > b` 就替换位置，即将小的放到前面。
    * `sort` 操作：与堆相反，`sort` 后面的比较表达式就表示了其升序还是降序（`a > b` 就是降序，`a < b` 就是升序）
  * 火山模型：对排序后的火山模型进行返回结果

#### OptimizeSortLimitAsTopN

* 基本操作：
  * 递归计划节点，将当前优化的节点进行返回，如果有 limit 计划同时，子计划为 `sort`，就使用当前节点（limit）以及子计划节点（sort）构建 `Top-N` 计划节点，进行返回
    * `children.emplace_back(OptimizeSortLimitAsTopN(child));` 这个递归操作，就重新遍历一边子节点，如果函数返回的是一个修改的节点，那新构建的计划树的节点就被修改了，相当于重构一边计划树
    * 返回 `Top-N` 的计划节点，这个计划节点的传入参数是 `limit` 的计划节点的元数据，以及排序节点的子节点，相当于将 `limit` 计划节点替换成了 `Top-N` 计划节点，子节点仍旧是 `sort` 节点，只是执行器不同。执行器会通过这个计划节点（Top-N）来获取需要的元数据、`order by` 与 `N`。



## project_4 - Concurrency Control

### 实验目的

* 实现一个锁管理器，对所有事务的锁进行管理。根据隔离级别以及事务状态和表行的状态进行授予锁（2PL）。同时对事务间的等待构建等待图，判断是否有死锁存在。
  * 行锁：加锁、取消锁
  * 表锁：加锁、取消锁
  * 等待图：检测、修改图
* 死锁检测：使用事务之间对表锁或行锁的等待关系，构建事务的等待图。死锁检测拥有回滚事务的功能，如果成环，则回滚事务（搜索等待图使用的是深度有先搜索）
* 并发事务：顺序扫描、插入和删除操作。增加锁

### 实验内容

* 锁管理器需要实现的部分：
  * 表锁：因为并发操作，所以需要根据隔离级别以及事务的状态进行上锁和解锁
  * 行锁：同样因为并发操作，也需要根据隔离级别以及事务的状态进行上锁和解锁
  * 等待图构建：加入边，删除边
  * 死锁检测：检测成环
  * 维护行锁表锁的集合
* 死锁检测：深度优先遍历去查找死锁

### 实验外内容

* 事务管理器：
* 事务：

### 实验要点

#### LockManager

**LockManager 的本质就是管理所有表的锁定请求和行锁请求，同时根据这些请求去检测是否存在成环的事务等待关系（遍历表锁请求集合和行锁请求集合），同时操作事务自身的表锁和行锁，存储事务请求的行锁和表锁集合**

* 表锁：

  * 上锁：先判断事务的隔离级别以及事务状态和加锁的类别

    * 读未提交的隔离级别：（会发生脏读、幻读、不可重复读）
      * 锁的类别（共享锁有关的锁）都会回滚：不允许读，因为会造成脏读
      * `2PL` 中，收缩阶段不允许上排他锁，一定不会上读锁，前者判断了读锁。**`2PL` 收缩（SHRINKING）不允许上锁**
      * 这个隔离级别只能上排他锁，为了防止脏读
    * 读已提交的隔离级别：（会发生幻读、不可重复读）
      * 该阶段只需要判断**收缩阶段**只能上共享锁，**不能上排他锁**
    * 重复读的隔离级别：（会发生幻读）
      * 不允许收缩状态，因为使用的是快照读，每次读取的是一个快照，所以不需要收缩。
      * MySQL 中使用了**范围锁保证了不发生幻读**，同时这个隔离级别是 MySQL 默认的隔离级别，使用了范围锁，保证了这个隔离级别等同于可序列化的隔离级别

    * 使用无序哈希表（加速查找）构建了一个表对应的锁请求序列，这个哈希表存储了每个表锁拥有的要锁定该表的请求序列（多个请求：不同事务）
    * 锁降级：当找到表锁对应的集合之后，锁定请求序列，解锁表锁哈希表。
    * 锁升级：再次向该表获取锁的时候需要锁升级操作
      * 当前表的请求序列的升级操作必须是本事务的否则只能进行回滚无法进行升级。
      * 锁升级的情况，上一次请求时的锁必须比当前请求的锁级别低，否则回滚
      * 将锁在请求队列中更新，同时更新表锁集合
      * 为当前事务的锁升级重新创建请求，加入到未被授予锁的请求的位置（**授予有序（时间顺序）排列，好根据时间顺序判定当前锁能否授予**）
      * 修改当前表的更新标志
      * 同时判断前方已被授予锁的事务，能否让当前事务进行锁升级（**同表锁是否冲突，如前方授予了排他锁，当前事务就不能进行锁升级，只能进行等待前方事务释放锁**）
      * 如果本身没有该事务的锁，就初始化一个请求，进行上锁（上锁同时也需要判断前方被授予的锁能不能让当前事务上锁）

  * 解锁：与加锁不同，解锁需要先判断表是否有请求队列，是否上锁

    * 先获取事务的行锁，然后判断是否有需要释放的行锁，如果没有，就说明事务（**隐式回滚**，程序出现问题或其他原因导致事务无法成功提交）出现了问题，就需要回滚。
    * 知道事务有锁后，去获取事务表对应的行锁，然后释放本事务被授予的表锁请求（遍历表锁对应的请求列表）
    * 释放锁，就等于事务的状态改变了（`2PL` 中**释放锁**的时候就变成了**收缩阶段**）。**注意：读已提交的隔离级别，只有判断释放排他锁才算收缩阶段（事务在收缩阶段仍旧可以上共享锁来避免读写冲突）**
* 行锁：

  * 上锁：同样先判断隔离级别、上锁类型和事务状态
    * 判断能否上锁
      * 行锁只有共享和排他两种锁，其他锁的类型全部回滚
      * 读未提交的状态只能上排他锁，其他锁的类型全部回滚
      * 读未提交的收缩状态只能释放锁（本身只能上排他锁，区别于读已提交）
      * 读已提交的状态，只能上共享锁，其他类型全部回滚
      * 可重复读的隔离级别，不存在收缩状态
      * 读未提交状态，不能上共享锁，只能上排他锁，同时收缩阶段不能上锁
      * 读已提交的收缩阶段，除了共享锁相关的锁，其他都不能上
      * 重复读，没有收缩状态，一直持有共享锁
      * 只有表锁上了排他锁，才能给行上排他锁
    * 其他与表锁相同
  * 解锁，同表锁相同
* 检查死锁：
  * 构建等待图：
    * 将等待的边（有向）的事务插入等待图中，等待图存储规则 `<txn, list<txn>>` 一个点对应的多条边

  * 判断成环：
    * 遍历事务的集合：深度优先遍历，去遍历每个节点的边的事务，如果集合中连续存在两个，说明有环，每点的多条边的事务点的集合会进行排序（深度优先），使用回溯法，成为安全节点之后需要清除集合中的记录，同时移入到安全集合中。
    * 如果存在环（即深度优先遍历返回了 `true`），就需要对激活图（成环的环）找到最新的事务，进行操作。
  * 回滚事务后删除等待图的边：
    * 删除与当前回滚事务有关的边（等待图当前事务对应的事务集合（以当前事务为起点的其他事务），等待图中其他事务到当前事务的边（该事务等待的事务））
    * 循环检测：
      * 获取表中被授予的锁（在授予锁的时候，是根据事务的先后来进行排序的，所以后面的锁（未授予锁）要等待前面的事务完成，这样边集合就可以直接加入 <未被授予的事务，被授予的事务> 构成一个等待图的边）未授予的锁需要等待前面所有被授予的锁。因此产生边集合<未被授予的锁， 前面被授予的锁>。所以等待图的构成是 <当前是事务，等待前方完成事务的集合>
      * 行锁与表锁相同，同时二者需要保存事务与表、行的映射，因为回滚事务的时候，需要将事务的所有**锁全部释放**
      * 获取事务集合中的成环的**最新事务**，设置回滚，同时删除等待图中与该事务有关的边，以及解锁表锁，行锁，同时唤醒等待获取该表和行的事务线程。

* 锁授予：当前要上的锁和已经存在的锁的类型进行授予。
  * 遍历当前表的每一个请求（被授予的锁是按照先后顺序排列的），查看被授予的锁的类型
  * 如果前方有授予的锁，需要判断前方锁的类型
  * 如果前方没有被授予的锁（第一个未被授予锁的请求），未被授予的锁不是该事务的锁，那也不能进行授予，需要排在后面去等待
  * 如果是该事务（第一个未被授予锁的请求），就授予锁

* 表锁集合的操作（删除和添加锁）：封装事务自身的操作（相当于工厂模式）
  * 调用事务自身表锁的集合进行插入和删除操作（使用 unordered_map 自身的 `insert` 操作和 `erase` 操作，不判断其实是否存在，因为存储的不同，这个只存储了表的 `oid`）

* 行锁集合的操作（删除和添加锁）：与表锁不同，这个操作是获取事务的表锁集合，通过自身的插入函数进行操作。其实也可以写到事务中
  * 获取事务的行锁集合 <表 `oid`，表对应的行 `rid`>，同时使用所管理器的插入操作和删除操作
    * 插入删除操作：根据事务的行锁集合找到请求中表对应的行锁集合，判断集合中是否存在，然后进行插入，因为可能不存在表对应的行锁，所以需要判断然后为表创建新的行锁集合。


**锁定的原理，是通过锁请求的是否被授予，来判断是否能加锁（在访问表锁的集合的时候是需要加锁的，行锁也同样），根据这些状态标志，来判断能否访问实际的数据库内容。**

#### Concurrent Query Execution

##### SeqScanExecutor

* 根据事务的隔离级别在初始化的时候进行锁表，除读未提交外都进行意图共享锁（是读取操作），`读未提交只能加排他锁` ，避免脏读。
* 调用执行器上下文中的锁管理器进行加锁

##### InsertExecutor

* 不需要根据事务的隔离级别，因为都是上排他锁（插入操作），给表上意图排他锁，同时在插入的过程中，还需要对表中的行上行锁（排他锁，防止其他操作访问，该插入的数据，避免幻读，类似于范围锁），但是行的 `rid`，是插入数据提供的，不是从数据库中获取的，因为数据库中不存在
* 调用执行器上下文中的锁管理器进行加锁

##### DeleteExecutor

* 删除操作同样不需要根据表的隔离级别进行上锁，统一上意图排他锁，同时在删除的过程中同样对行加排他锁来避免幻读和读脏数据。
* 调用执行器上下文中的锁管理器进行加锁





