# 数据库面试题







# 综合面试题

## 简述题

### 给定ab两个文件各存放50亿个url每个url各占64字节，内存限制是 4G 如何找出ab文件共同的ur?

#### 外部排序

由于题目给定的内存限制是4G，而文件a和文件b的大小分别为50亿 * 64字节，因此无法将它们同时加载到内存中进行处理。因此，我们需要采用一种基于磁盘的算法来解决这个问题。

一种常见的基于磁盘的算法是外部排序（External Sorting），它可以将大量数据分成若干个小块，然后对每个小块进行内部排序，最后使用归并排序的方式将这些小块合并成一个有序的序列。在本题中，我们可以将文件a和文件b分别分成若干个小块，对每个小块进行排序，并将排序后的结果存储到磁盘中。然后，我们可以使用归并排序的方式将这些排序后的小块合并成一个有序的序列，并在合并的过程中找到共同的url。

具体步骤如下：

1. 将文件a和文件b分别分成若干个小块，每个小块大小为4G/2 = 2G。可以使用外部排序算法对每个小块进行内部排序，并将排序后的结果存储到磁盘中。
2. 对于每个排序后的小块，使用哈希表来记录其中出现过的url和出现的次数。由于url的数量可能非常大，因此需要使用哈希表来对它们进行统计。
3. 对于两个文件中出现的所有url，将其在哈希表中的出现次数相加，如果结果大于等于2，则说明它是共同的url。将共同的url存储到磁盘中。
4. 使用归并排序的方法将所有的共同的url合并成一个有序的序列。由于共同的url的数量可能非常大，因此需要使用外部排序算法对它们进行排序，并将排序后的结果存储到磁盘中。
5. 返回排序后的共同的url列表作为结果。

由于外部排序算法的时间复杂度为O(nlogn)，而哈希表的时间复杂度为O(1)，因此上述算法的时间复杂度为O(nlogn)，其中n是url的数量。由于每个小块的大小为2G，因此需要使用磁盘空间来存储排序后的结果和共同的url列表。

#### 哈希索引的递归分解

使用哈希索引的递归分解也可以解决这个问题，但是需要注意内存使用的问题。

这种方法的基本思路是，将两个文件分别分成若干个小块，对每个小块进行哈希索引构建。具体步骤如下：

1. 将文件a和文件b分别分成若干个小块，每个小块大小为内存限制的一半，即2G。
2. 对于每个小块，使用哈希表来构建哈希索引，将其中的url映射到对应的小块中。
3. 对于文件a中的每个小块，检查其中的url是否在文件b的哈希索引中出现过。如果出现过，则将其加入到共同的url列表中。
4. 对于文件b中的每个小块，检查其中的url是否在文件a的哈希索引中出现过。如果出现过，则将其加入到共同的url列表中。
5. 对于共同的url列表，对其进行排序并存储到磁盘中。

需要注意的是，使用哈希索引的递归分解仍然需要使用哈希表来构建哈希索引，因此需要注意内存的使用。如果哈希表的大小超过了内存限制，就需要将其中的一部分数据保存到磁盘中。此外，由于需要将两个文件都分成若干个小块，因此需要使用磁盘空间来存储这些小块。因此，这种方法仍然需要使用大量的磁盘空间，并且可能需要进行多次磁盘读写操作，效率较低。