# C++面试题

## 1.全局变量初始化为0和非零，在存储区方面有什么区别

1. BSS段（Block Started by Symbol）：当全局变量初始化为0时，编译器通常将其分配到BSS段。BSS段是用于存储未初始化或初始化为零值的静态数据的一部分。在程序加载时，操作系统会为BSS段分配内存，并将其初始化为零。这意味着全局变量在程序启动时会自动被初始化为零，不需要额外的初始化操作。
2. 数据段：当全局变量初始化为非零值时，编译器通常将其分配到数据段。数据段存储已经初始化的全局变量和静态变量。在程序加载时，操作系统会为数据段分配内存，并将变量的初始值存储在相应的内存位置。

从存储区的角度来看，全局变量初始化为0的情况下，不需要在程序运行时进行额外的初始化操作，因为操作系统已经将其初始化为零。这可以节省一些初始化的时间和资源。而全局变量初始化为非零值时，需要在程序运行时将初始值存储到相应的内存位置。

同时 `static` 进行初始化的时候，是 0 初始化

## 2.类成员声明为static，除了共享，还有什么用？

1. 共享数据：静态成员在类的所有对象之间是共享的。这意味着无论创建多少个类的实例，静态成员只有一份拷贝。这对于需要在类的多个对象之间共享数据的情况非常有用。
2. 访问控制：静态成员可以访问类的所有非静态成员，包括私有成员。这使得静态成员可以用于实现一些与类的实例无关的功能，例如工具函数或静态辅助方法。
3. 类级别操作：静态成员可以用于执行类级别的操作，而不需要实例化类。这意味着可以通过类名直接访问静态成员，而无需创建对象。这对于实现与类相关的实用方法、常量或枚举值等非对象特定功能非常有用。
4. 全局访问：静态成员可以在类的外部访问，因为它们归属于类本身而不是对象。这使得其他类或代码可以直接访问和使用静态成员，而无需通过类的实例。
5. 延迟初始化：静态成员可以用于实现延迟初始化的功能。通过将静态成员与静态初始化块结合使用，可以在首次访问静态成员时进行初始化操作。

## 3.四则运算实现





# Go 面试题

## 1.Go slice、map 实现，GC 原理

1. Slice（切片）：
   - Slice是对数组的一种抽象，它提供了动态大小的、灵活的视图。
   - Slice由三个部分组成：指针、长度和容量。
   - 指针指向底层数组的起始位置，长度代表Slice当前包含的元素数量，容量表示Slice从起始位置到底层数组末尾的可访问元素数量。
   - Slice的底层数组可能比Slice的容量大，这使得Slice可以动态增长。
   - 在运行时，当Slice的容量不足时，会自动分配一个更大的底层数组，并将原有元素复制到新数组中。
   - GC会负责回收底层数组中不再被引用的内存空间。
2. Map（映射）：
   - Map是一种键值对的集合，类似于其他语言中的字典或关联数组。
   - Map的键和值可以是任意类型，但键必须是可比较的。
   - Map的底层实现使用了哈希表（Hash Table）。
   - GC会自动检测不再被引用的Map对象，并回收相关的内存空间。
   - 在GC过程中，如果Map对象的键或值是指针类型，并且没有其他引用指向它们，那么它们也会被垃圾回收。

GC（垃圾回收）原理：

- Go语言使用了一种称为"标记-清除"（Mark and Sweep）的垃圾回收算法。
- GC会周期性地扫描堆上的对象，标记所有仍然被引用的对象。
- 在标记阶段完成后，GC会清除所有未被标记的对象，释放它们所占用的内存空间。
- Go的GC实现是并发的，即垃圾回收过程与程序的执行可以同时进行，以减少对程序性能的影响。
- Go的GC还使用了分代回收（Generational Collection）的概念，根据对象的存活时间将堆划分为不同的代，以优化垃圾回收的效率。

## 2.Go channel，Mutex，RwMutex

Go语言中的channel、Mutex和RWMutex是用于实现并发控制和同步的关键机制。它们的功能和用法如下：

1. Channel（通道）：
   Channel是Go语言中的通信机制，用于在不同的goroutine之间传递数据。通道提供了一种安全、同步的方式，确保数据的发送和接收操作在不同的goroutine之间进行。

   通道可以用于实现并发控制和同步，通过将数据发送到通道中，一个goroutine可以等待另一个goroutine接收该数据，从而实现了同步和协作。通道还提供了阻塞和非阻塞的发送和接收操作，以便控制并发的进行。

2. Mutex（互斥锁）：
   Mutex是Go语言中的互斥锁，用于保护共享资源在多个goroutine之间的互斥访问。只有拥有互斥锁的goroutine才能访问被锁定的资源，其他goroutine需要等待互斥锁释放后才能继续访问。

   通过在关键代码段前后使用Lock()和Unlock()方法，可以保证同一时间只有一个goroutine能够访问被保护的共享资源。互斥锁提供了排他性的访问控制，确保数据的一致性和完整性。

3. RWMutex（读写互斥锁）：
   RWMutex是Go语言中的读写互斥锁，用于在读多写少的场景中提供更高的并发性能。与Mutex不同，RWMutex允许多个goroutine同时读取共享资源，但只允许一个goroutine进行写操作。

   当一个goroutine获取到写锁时，其他goroutine无法读取或写入共享资源，直到写锁释放。当一个goroutine获取到读锁时，其他goroutine可以继续获取读锁，但不能获取写锁。这样可以提高读操作的并发性能。

   RWMutex通过使用RLock()和RUnlock()方法获取和释放读锁，使用Lock()和Unlock()方法获取和释放写锁。

这些并发控制和同步机制在Go语言中广泛应用于多个goroutine之间的安全访问共享资源，确保数据的一致性和正确性。根据具体的需求和并发模式，可以选择适当的机制来实现并发控制和同步。





# 算法面试题

## 简述题

### 1.简述快排

* 分治的思想，随机选取一个位置最为划分值的点，左半部分的值都要小于划分点，右半部分的值都要大于划分的点，通过位置交换来进行左右部分数值的交换，划分完成之后调用两次这个划分函数在分别交换左右区间的数据。



## 本地IDE编写

### 1.合并有序链表

```c++
#include <iostream>
#include <vector>

using namespace std;

class Node {
public:
    int val;
    Node *next;

    Node():next(nullptr), val(0){};
    Node(int val) {
        this->val = val;
        this->next = nullptr;
    }
};

Node* mergeList(Node* L1, Node* L2) {
    Node* Head = new Node();
    Node* head = Head;
    // 对L1 L2进行合并
    while (L1!= nullptr && L2 != nullptr) {
        if (L1->val < L2->val) {
            head->next = L1;
            L1 = L1->next;
            head = head->next;
        } else {
            head->next = L2;
            L2 = L2->next;
            head = head->next;
        }
    }
    if (L1 != nullptr) {
        while (L1 != nullptr) {
            head->next = L1;
            L1 = L1->next;
            head = head->next;
        }
    }
    if (L2 != nullptr) {
        while (L2 != nullptr) {
            head->next = L2;
            L2 = L2->next;
            head = head->next;
        }
    }
    head->next = nullptr;
    return Head->next;
}

int main() {
    vector<int> l1 = {1, 3, 4, 5, 6};
    vector<int> l2 = {1, 3, 3, 6, 9, 12};
    Node *L1 = new Node();
    Node *ll1;
    ll1 = L1;
    Node *L2 = new Node();
    Node *ll2;
    ll2 = L2;
    for (auto i: l1) {
        ll1->next = new Node(i);
        ll1 = ll1->next;
    }
    for (auto i: l2) {
        ll2->next = new Node(i);
        ll2 = ll2->next;
    }

    Node * link = mergeList(L1->next, L2->next);
    for (;link != nullptr; link = link->next) {
        cout << link->val << " ";
    }
}
```



## 具体算法题

### 1.求给定的数组中和为0的最长子序列的长度

* 不能用滑动窗口做，因为滑动窗口的 **收缩条件** 是 **无法确定的**





# 分布式存储面试题

## 1.CAP理解，解决方案

CAP理论是分布式系统设计中的一个基本原则，它指出在一个分布式系统中，无法同时满足一致性（Consistency）、可用性（Availability）和分区容忍性（Partition Tolerance）这三个属性。下面我将对CAP理论进行解释，并提供一些解决方案。

1. 一致性（Consistency）：一致性要求系统在任何时刻都应该保持一致的数据状态。即，如果在一个节点上进行了数据的修改操作，那么所有的节点都应该能够看到这个修改。在分布式系统中，实现强一致性可能会导致性能和可用性的牺牲。
2. 可用性（Availability）：可用性要求系统在任何时刻都应该对用户的请求做出响应，即系统不应该出现长时间的不可用状态。在分布式系统中，实现高可用性可能会放宽一致性的要求。
3. 分区容忍性（Partition Tolerance）：分区容忍性指系统可以继续运行，即使网络中的某些部分无法通信或发生分区。在分布式系统中，网络故障和节点之间的延迟是不可避免的，因此需要保证系统在分区发生时仍能正常运行。

根据CAP理论，分布式系统只能同时满足其中的两个属性，无法同时满足三个。根据实际需求和应用场景，可以选择以下解决方案：

- CA: 强一致性和高可用性。在这种情况下，系统会优先保证数据的一致性和可用性，但可能会受到分区故障的影响。传统的关系型数据库系统如MySQL通常追求CA。
- CP: 强一致性和分区容忍性。在这种情况下，系统会优先保证数据的一致性和分区容忍性，但可能会牺牲一部分可用性。一些分布式数据库如Apache Cassandra追求CP。
- AP: 高可用性和分区容忍性。在这种情况下，系统会优先保证可用性和分区容忍性，但可能会牺牲一部分数据的一致性。一些分布式系统如Amazon Dynamo追求AP。

需要根据具体的业务需求和系统要求来选择适合的CAP属性组合。对于不同的应用场景，可能会采用不同的解决方案，包括使用副本、数据分片、数据同步机制、分布式事务等技术手段来实现所需的一致性、可用性和分区容忍性。

## 2.Raft实现，和Paxos区别

Raft和Paxos都是一致性算法，用于解决分布式系统中的数据一致性问题。它们的目标都是在面对网络故障和节点故障的情况下，保证分布式系统的一致性。下面是Raft和Paxos之间的一些区别：

理解和可理解性：Raft的设计目标是提供一种易于理解和可实现的一致性算法。相比之下，Paxos的算法描述相对较为复杂，较难理解和实现。

领导者选举：在Raft中，领导者（Leader）的选举过程相对简单，任何一个候选节点（Candidate）获得了大多数节点的选票即可成为新的领导者。而在Paxos中，领导者的选举过程相对复杂，需要通过多轮的提议和接受阶段来决定。

一致性模块：Raft将一致性算法分解为三个模块，即领导选举、日志复制和安全性检查。这种模块化设计有助于理解和实现。而Paxos将一致性算法作为一个整体，没有明确的模块划分。

日志复制：在Raft中，领导者负责接收客户端请求，并将这些请求以日志的形式复制到其他节点上。一旦日志被大多数节点确认复制，就可以应用到状态机中，实现数据的一致性。而在Paxos中，提议的接受过程更为复杂，涉及多个提议者和接受者之间的交互。

总的来说，Raft相对于Paxos来说更易于理解和实现，并且具有更清晰的模块划分。这使得Raft在实际应用中更受欢迎，并在一些分布式系统（如etcd、Consul等）中被广泛采用。然而，Paxos作为一种经典的一致性算法仍然具有重要的研究和理论意义。

## 3.Kafka分片、共识

Kafka是一个分布式的消息中间件系统，它使用分片和共识机制来实现高吞吐量和容错性。下面是Kafka中分片和共识的解释：

1. 分片（Partitioning）：
   Kafka将消息数据分为多个分片，每个分片都是一个有序、不可变的日志序列。每个分片在Kafka集群中被复制到多个节点上，以提供冗余和容错性。分片的作用是将负载分散到多个节点上，实现消息的并行处理和水平扩展性。

   分片机制使得Kafka能够处理大规模的数据流，并允许多个消费者并行地消费消息。每个分片在逻辑上形成一个独立的消息队列，消费者可以独立地读取和处理其中的消息。

2. 共识（Consensus）：
   Kafka使用ZooKeeper作为协调服务来实现共识机制。ZooKeeper保证了Kafka集群中的各个节点之间的一致性和可靠性。它协调分布式节点的选举、配置管理和状态同步，确保Kafka集群的稳定运行。

   共识机制还涉及到Kafka的生产者和消费者之间的协调。生产者将消息写入Kafka的分片中，并通过ZooKeeper来追踪分片的元数据和分布情况。消费者通过ZooKeeper获取分片的信息，并以消费者组的形式进行协作消费。ZooKeeper帮助消费者进行分区分配，以实现负载均衡和故障转移。

通过分片和共识机制，Kafka实现了高度可扩展、高吞吐量和容错性的特性。分片提供了并行处理和水平扩展的能力，而共识机制保证了Kafka集群的一致性和可靠性。这使得Kafka成为处理大规模实时数据流的理想选择。

## 4.REST，RPC 比较

REST（Representational State Transfer）和RPC（Remote Procedure Call）是两种常见的通信协议和架构风格，用于构建分布式系统和实现不同服务之间的通信。它们有以下几个方面的比较：

1. 架构风格：
   - REST：REST是一种基于HTTP协议的架构风格，强调资源的概念和状态转移。它使用统一的接口（如GET、POST、PUT、DELETE）来操作资源，通过URL定位资源，并使用HTTP状态码表示操作结果。
   - RPC：RPC是一种远程调用的架构风格，其目标是使远程过程调用像本地调用一样简单。它通过定义接口和方法签名来描述远程服务，客户端可以通过调用远程方法来请求服务端的功能。
2. 通信协议：
   - REST：REST通常使用HTTP作为通信协议，利用HTTP的标准方法（GET、POST、PUT、DELETE）来进行资源操作，并使用URL来定位资源。
   - RPC：RPC可以使用不同的传输协议，如TCP、HTTP、JSON-RPC、gRPC等。它通常使用自定义的协议和编码方式进行通信。
3. 数据格式：
   - REST：REST通常使用JSON或XML等可读性较好的数据格式进行数据交换，这使得它易于理解和调试。
   - RPC：RPC可以使用不同的数据格式，如二进制格式、JSON、XML等，具体取决于所使用的传输协议和编码方式。
4. 可扩展性：
   - REST：REST具有良好的可扩展性，通过使用HTTP的特性（如缓存、代理、负载均衡）以及多级API设计，可以实现高度可伸缩的系统。
   - RPC：RPC的可扩展性取决于所选择的实现方式和协议。一些RPC框架提供了负载均衡、服务发现和自动重试等功能，以支持大规模系统的扩展。
5. 开发体验：
   - REST：REST的开发相对简单，使用基于HTTP的标准方法和数据格式，易于理解和使用。它也具有良好的可读性和可测试性。
   - RPC：RPC的开发相对复杂，需要定义接口和方法签名，并使用特定的编码和协议。它可能需要更多的配置和工具支持，但对于复杂的系统和性能要求较高的场景，RPC可能更适合。

需要注意的是，REST和RPC并不是相互排斥的选择，而是根据具体的需求和系统架构来选择合适的通信方式。在一些场景中，REST和RPC可以结合使用，例如使用REST作为外部API的公共接口，而内部服务之间使用RPC进行通信。

## 5.gRPC使用过程中遇到过哪些问题

在使用gRPC过程中，可能会遇到一些常见的问题。以下是几个可能的问题：

1. 版本兼容性问题：gRPC有多种语言实现，例如gRPC-Java、gRPC-Go、gRPC-C++等，不同语言的版本可能存在兼容性差异。如果使用不同版本的gRPC库进行开发和通信，可能会遇到协议不匹配或功能不一致的问题。
2. 配置和部署问题：gRPC需要正确配置和部署服务端和客户端，包括选择适当的序列化格式、认证和授权机制等。配置和部署的不正确或不一致可能导致通信失败或安全问题。
3. 性能调优问题：gRPC在性能方面表现出色，但在大规模系统中，仍可能需要进行性能调优。例如，选择适当的负载均衡策略、调整请求大小和并发度，以及优化网络连接等方面都可能涉及到性能调优的问题。
4. 错误处理和调试问题：gRPC使用状态码和错误对象来表示请求和响应的状态，但在处理错误和调试时，可能需要详细的错误信息和调试日志。确保正确处理错误，并提供适当的日志和调试信息，可以帮助快速定位和解决问题。
5. 安全性问题：gRPC支持使用TLS/SSL进行安全通信，并提供认证和授权机制。在使用gRPC时，确保适当配置和使用安全功能，以保护通信的安全性和数据的机密性。
6. 跨平台兼容性问题：gRPC支持多种平台和语言，但在跨平台开发时，可能会遇到平台特定的问题。例如，某些操作系统或语言可能不支持某些gRPC功能或特性，需要进行适当的处理和兼容性测试。

对于遇到的问题，可以参考gRPC官方文档、社区讨论和示例代码等资源，寻找解决方案或寻求帮助。此外，使用调试工具和日志记录来收集和分析问题的相关信息也是解决问题的重要手段。





# 数据库面试题

## 1.MySQL 事务，MVCC 实现

1. MySQL事务：
   MySQL中的事务是一组数据库操作，这些操作要么全部成功执行，要么全部回滚（撤销）。事务具有以下四个特性，通常被称为ACID特性：

   - 原子性（Atomicity）：事务中的操作要么全部执行成功，要么全部回滚，没有中间状态。
   - 一致性（Consistency）：事务开始前和结束后，数据库的状态必须保持一致。
   - 隔离性（Isolation）：并发执行的事务之间应该相互隔离，每个事务都应该感知不到其他事务的存在。
   - 持久性（Durability）：一旦事务提交，其结果应该持久保存，即使系统崩溃也不会丢失。

2. MVCC实现：
   MVCC是一种并发控制机制，用于在多个事务并发执行时提供高度的隔离性。它基于对数据行版本的管理，每个事务在读取数据时看到的是特定时间点的数据快照。

   在MySQL中，MVCC是通过以下两个机制实现的：

   - 版本号（Versioning）：每个数据行都会分配一个版本号，用于标识数据的修改历史。当一个事务开始时，它会记录当前的系统版本号，事务中的查询操作只能看到在该版本号之前已经提交的数据版本。
   - Undo日志（Undo Log）：为了支持事务的回滚操作，MySQL使用了Undo日志。在事务执行修改操作时，会在Undo日志中记录修改前的数据版本，以便在回滚时可以还原到之前的状态。

   当一个事务需要读取数据时，MySQL会根据事务的版本号和数据行的版本号来判断是否可见。如果数据行的版本号早于事务的版本号，那么该数据行是可见的。如果数据行的版本号晚于事务的版本号，那么该数据行是不可见的，事务需要查找之前的版本来获取可见的数据。

   MVCC提供了高度的并发性能和隔离性，不同的事务可以同时读取和修改数据，而不会相互干扰。它是MySQL中实现ACID特性的重要机制之一。

需要注意的是，MVCC仅适用于使用InnoDB存储引擎的表，而不适用于其他存储引擎（如MyISAM）。因此，在使用MySQL时，确保选择合适的存储引擎以支持事务和MVCC功能。

## 2.MySQL 索引实现，B+ Tree 节点文件结构

MySQL使用B+树数据结构来实现索引。B+树是一种平衡的树结构，它具有以下特点：每个节点可以存储多个键和对应的值，节点之间通过指针连接，树的高度相对较低，提供高效的查找和范围查询性能。下面是MySQL索引实现中B+树的节点文件结构：

1. 叶子节点（Leaf Node）：
   叶子节点存储实际的索引数据，即键和对应的值（行的主键或辅助索引的键值）。在MySQL的B+树实现中，叶子节点之间通过双向链表连接，以支持范围查询和顺序遍历。

   叶子节点的文件结构通常包含以下信息：

   - 键值（Key）：用于进行索引查找和排序。
   - 行指针（Row Pointer）：指向实际数据行的位置，可以是物理地址或逻辑标识符。
   - 其他辅助信息：例如前后指针，用于双向链表连接。

2. 非叶子节点（Internal Node）：
   非叶子节点用于存储索引键的范围信息和指向下级节点的指针。它们的作用是提供一级一级的索引查找路径，最终指向叶子节点。

   非叶子节点的文件结构通常包含以下信息：

   - 索引键（Key）：用于进行索引查找和分割数据范围。
   - 子节点指针（Child Pointer）：指向下级节点的指针，按照键的大小顺序排列。

3. 根节点（Root Node）：
   根节点是B+树的顶层节点，它包含指向下级节点的指针。根节点在文件中的位置是固定的，可以通过文件头部的元数据进行查找。

4. 文件头部（File Header）：
   文件头部存储B+树的元数据信息，例如根节点的位置、树的高度、节点大小等。它提供了对整个B+树结构的基本描述和定位信息。

通过这种节点文件结构，MySQL的B+树索引实现可以高效地进行索引查找、范围查询和数据排序操作。B+树的平衡性和节点文件结构的设计使得索引在插入、删除和更新操作时能够自动调整和维护树的平衡状态，以保持良好的性能和可靠性。





# 计算机网络面试题

## 1.tcp怎么保证可靠

1. 应答和重传（Acknowledgment and Retransmission）：每当发送方发送一个数据段（segment）时，接收方会确认收到数据段。如果发送方在一定时间内没有收到确认（ACK），它会假设数据丢失，并重新发送数据段。这确保了数据的可靠传输。
2. 序列号和确认号（Sequence Numbers and Acknowledgment Numbers）：每个数据段都有一个唯一的序列号，用于将数据段按序传递给应用程序。接收方通过确认号来指示已经成功接收到的最后一个字节的序列号。发送方根据确认号知道哪些数据已成功传输，哪些需要进行重传。
3. 流量控制（Flow Control）：TCP使用滑动窗口机制来控制发送方和接收方之间的数据流量。接收方可以告诉发送方它的可用缓冲区大小，发送方根据接收方的窗口大小来控制发送的数据量，避免过载接收方。
4. 拥塞控制（Congestion Control）：TCP使用拥塞控制算法来避免网络拥塞。它通过动态调整发送速率和窗口大小来响应网络的拥塞情况，以确保网络资源的合理利用，避免数据丢失和延迟。
5. 超时和重传定时器（Timeout and Retransmission Timer）：发送方在发送数据段后启动一个定时器。如果在定时器超时之前未收到确认，发送方会假设数据丢失，并重新发送数据段。定时器的超时时间根据网络延迟动态调整，以适应不同的网络条件。

## 2.发一个报文就会收到一个ack吗？发4个tcp报文，会收到4个ack吗？

在TCP中，发送一个报文并不一定会立即收到一个ACK（确认应答）。TCP使用了一种称为"累计确认"（Cumulative Acknowledgment）的机制。

当接收方成功接收到一个TCP报文段后，它会发送一个ACK，确认已经收到了该报文段和该报文段之前所有已成功接收的报文段。这意味着，如果接收方成功接收了多个连续的报文段，它只会发送一个ACK来确认这些报文段的接收。

所以，对于你的第一个问题，发送一个报文并不一定会立即收到一个ACK。接收方可能会延迟发送ACK，以便在一定时间内收集多个报文段一起确认。

对于你的第二个问题，如果发送了4个TCP报文段，接收方可能会合并这些报文段的确认，并发送一个ACK来确认这4个报文段的接收。

需要注意的是，ACK的发送时间和合并策略可能会根据TCP实现和网络条件而有所不同。有些实现可能会立即发送ACK，而有些实现可能会延迟发送ACK以实现更好的性能或网络利用率。

## 3.seq是怎么变化的？每次加一？是吗？你确定？

在TCP中，序列号是用来标识报文段中的数据字节的。TCP使用了一个32位的序列号字段来表示序列号。序列号的初始值是由双方在建立TCP连接时协商确定的。

序列号的变化是基于发送的数据字节数来确定的。每个TCP报文段都包含一个序列号，表示这个报文段的第一个数据字节在整个数据流中的位置。

发送方的序列号会根据发送的数据字节数进行增加。它会根据已经发送的数据字节数和下一个要发送的数据字节数来计算新的序列号。具体而言，它使用的是累加法，即当前的序列号加上已发送的数据字节数。

例如，如果发送方的初始序列号是1000，并且已经发送了100个字节的数据，那么下一个报文段的序列号将是1100（1000 + 100）。

需要注意的是，序列号是一个循环增加的计数器，当达到最大值（2^32-1）后会重新从0开始。这是为了处理数据包在网络上的往返和重传时的序列号回绕问题。

总结起来，TCP的序列号根据发送的数据字节数进行增加，并且支持循环增加以处理序列号回绕的情况。





# Linux 面试题

## 1.Linux 进程通信，pipe 原理

在Linux中，管道（pipe）是一种进程间通信（IPC）的机制，用于在两个相关的进程之间传递数据。管道提供了一个单向的、字节流的通道，其中一个进程作为写入端，另一个进程作为读取端。下面是管道的基本原理：

1. 创建管道：使用系统调用`pipe()`创建一个管道。该调用会返回两个文件描述符，一个用于读取端（读文件描述符），一个用于写入端（写文件描述符）。这两个文件描述符可以用于在两个相关的进程之间传递数据。
2. 进程关系：在管道中，通常有一个父进程和一个子进程。父进程通过`fork()`系统调用创建子进程。子进程会继承父进程的文件描述符，包括管道的读写文件描述符。
3. 数据传递：父进程通过写入文件描述符向管道中写入数据，子进程通过读取文件描述符从管道中读取数据。管道中的数据以字节流的形式进行传递，没有固定的消息边界。
4. 管道缓冲区：管道内部有一个缓冲区，用于存储待读取的数据。当写入端写入数据时，数据首先存储在缓冲区中。当读取端读取数据时，数据从缓冲区中被移出。如果缓冲区为空，读取端的读取操作会被阻塞，直到有数据可读。类似地，如果缓冲区已满，写入端的写入操作会被阻塞，直到有空间可写入。
5. 管道的关闭：当写入端的所有写入文件描述符被关闭时，读取端会收到一个特殊的条件，即读取到文件结束标志（End-of-File，EOF）。这时读取端可以继续读取剩余的数据，并且在读取完所有数据后也会收到EOF。

需要注意的是，管道是一种半双工的通信机制，只能在一个方向上传递数据。如果需要双向通信，可以创建两个管道，分别用于不同的方向。

## 2.fork 内存占用，写时复制在Redis的应用

在讨论fork的内存占用和写时复制在Redis中的应用之前，先了解一下fork和写时复制的概念：

1. fork：`fork()`是一个系统调用，用于创建一个新的进程（子进程）。子进程是通过复制父进程的内存空间来创建的，包括代码、数据和堆栈等。在fork之后，父进程和子进程将并行执行，但拥有各自独立的内存空间。
2. 写时复制（Copy-on-Write，COW）：写时复制是一种延迟复制的技术。在fork之后，父进程和子进程共享相同的物理内存页。当父进程或子进程试图修改这些页中的内容时，才会进行实际的复制操作。这样可以避免在fork时立即复制整个内存空间，从而节省内存和时间。

现在我们来看一下写时复制在Redis中的应用：

Redis是一个内存数据库，它使用写时复制来实现持久化。Redis的持久化机制有两种方式：RDB（Redis Database）和AOF（Append-Only File）。

1. RDB持久化：当执行RDB持久化操作时，Redis会fork一个子进程来处理持久化过程。在fork时，子进程会继承父进程的内存空间，但实际的数据复制只会在需要修改数据时才发生，这就是写时复制的应用。这意味着在持久化期间，父进程和子进程之间的大部分内存是共享的，只有在修改数据时才会进行复制。
2. AOF持久化：AOF持久化是通过将所有写操作追加到一个日志文件中来实现的。当进行AOF重写或者启动时，Redis会fork一个子进程来处理日志文件的重写。在这个过程中，写时复制也被应用，子进程只有在需要修改数据时才会进行实际的复制操作。

写时复制在Redis中的应用使得持久化过程更加高效，减少了内存的占用和复制的开销。它允许Redis在不中断服务的情况下进行持久化，并且在持久化期间对内存的占用也相对较小。

需要注意的是，fork操作会占用一定的内存空间来存储父进程的内存快照，这可能会导致短暂的内存占用峰值。因此，在Redis使用持久化时，特别是对于大型数据集和频繁的持久化操作，需要合理配置系统的内存和监控内存使用情况，以确保系统的稳定性和性能。

## 3.Linux 根目录下各个文件夹作用

1. /bin：
   该目录包含了系统中最基本的可执行命令（二进制文件），如ls、cp、mv等。这些命令通常被所有用户和系统进程使用。
2. /boot：
   /boot目录包含启动系统所需的文件，例如内核（kernel）和引导加载程序（bootloader）。这些文件在系统引导时被使用。
3. /dev：
   /dev目录包含设备文件，用于与系统中的硬件设备进行交互。例如，硬盘、键盘和鼠标等设备在该目录下有相应的文件表示。
4. /etc：
   /etc目录包含系统的配置文件。系统管理员可以在此目录下找到各种配置文件，例如网络配置、用户账户配置、服务配置等。
5. /home：
   /home目录是用户的家目录（Home Directory）的父目录。每个用户在该目录下有一个独立的子目录，用于存储其个人文件和设置。
6. /lib和/lib64：
   这些目录包含系统所需的共享库文件（libraries），这些库文件为可执行程序提供了必要的功能和支持。
7. /media和/mnt：
   这些目录用于挂载可移动介质（如CD、DVD、USB驱动器）和其他文件系统。当插入可移动介质时，系统会自动将其挂载到这些目录下。
8. /opt：
   /opt目录用于安装可选软件包（optional packages）。一些第三方软件通常被安装在该目录下，并按照各自的目录结构进行组织。
9. /proc：
   /proc目录提供了系统和进程相关的运行时信息。该目录下的文件和子目录以虚拟文件和文件夹的形式存在，用于访问和监控系统状态。
10. /root：
    /root目录是系统管理员（root用户）的家目录。与其他用户的家目录不同，root用户的家目录位于根目录下。
11. /sbin：
    /sbin目录包含系统管理员使用的系统管理命令（二进制文件），如reboot、shutdown等。这些命令通常需要root权限才能执行。
12. /tmp：
    /tmp目录用于存储临时文件。在该目录下创建的文件通常在系统重启时会被清除。
13. /usr：
    /usr目录包含用户的应用程序和文件。它类似于一个次要的根目录，包含用户安装的软件、库文件、文档等。
14. /var：
    /var目录包含可变数据（variable data），包括日志文件、缓存文件、临时文件等。这些文件通常在运行时会被修改和更新。

## 4.Linux inode

在Linux文件系统中，inode（Index Node）是一个数据结构，用于表示文件或目录的元数据信息。每个文件和目录在文件系统中都有一个唯一的inode，用于标识和管理其相关的属性和数据。

inode包含了以下关键信息：

1. 文件类型：指示inode是文件、目录、符号链接等类型。
2. 文件权限：指定了文件的访问权限，包括所有者、群组和其他用户的读、写和执行权限。
3. 文件所有者和群组：记录了文件的所有者和所属群组的标识符。
4. 文件大小：表示文件的大小（以字节为单位）。
5. 时间戳：记录了文件的创建时间、修改时间和访问时间。
6. 硬链接计数：表示有多少个硬链接指向该inode，当该计数为0时，文件系统会释放该inode和相关的数据块。
7. 数据块指针：包含了指向存储文件数据的数据块的指针。

inode的设计使得文件系统可以高效地管理文件和目录的元数据。通过inode，文件系统可以快速定位和访问文件的相关信息，而不需要扫描整个文件系统。

值得注意的是，每个文件系统中的inode数量是有限的，这限制了文件系统中可创建的文件和目录的数量。不同的文件系统可以配置不同的inode数量，这取决于文件系统的设计和配置参数。当inode数量用尽时，文件系统将无法创建新的文件或目录，即使磁盘空间仍然可用。

总而言之，inode在Linux文件系统中起着关键的作用，用于存储文件和目录的元数据信息，包括权限、所有者、大小、时间戳等。通过inode，文件系统能够高效地管理和访问文件的相关信息。





# 综合面试题

## 1.给定ab两个文件各存放50亿个url每个url各占64字节，内存限制是 4G 如何找出ab文件共同的ur?

* **外部排序**

由于题目给定的内存限制是4G，而文件a和文件b的大小分别为50亿 * 64字节，因此无法将它们同时加载到内存中进行处理。因此，我们需要采用一种基于磁盘的算法来解决这个问题。

一种常见的基于磁盘的算法是外部排序（External Sorting），它可以将大量数据分成若干个小块，然后对每个小块进行内部排序，最后使用归并排序的方式将这些小块合并成一个有序的序列。在本题中，我们可以将文件a和文件b分别分成若干个小块，对每个小块进行排序，并将排序后的结果存储到磁盘中。然后，我们可以使用归并排序的方式将这些排序后的小块合并成一个有序的序列，并在合并的过程中找到共同的url。

具体步骤如下：

1. 将文件a和文件b分别分成若干个小块，每个小块大小为4G/2 = 2G。可以使用外部排序算法对每个小块进行内部排序，并将排序后的结果存储到磁盘中。
2. 对于每个排序后的小块，使用哈希表来记录其中出现过的url和出现的次数。由于url的数量可能非常大，因此需要使用哈希表来对它们进行统计。
3. 对于两个文件中出现的所有url，将其在哈希表中的出现次数相加，如果结果大于等于2，则说明它是共同的url。将共同的url存储到磁盘中。
4. 使用归并排序的方法将所有的共同的url合并成一个有序的序列。由于共同的url的数量可能非常大，因此需要使用外部排序算法对它们进行排序，并将排序后的结果存储到磁盘中。
5. 返回排序后的共同的url列表作为结果。

由于外部排序算法的时间复杂度为O(nlogn)，而哈希表的时间复杂度为O(1)，因此上述算法的时间复杂度为O(nlogn)，其中n是url的数量。由于每个小块的大小为2G，因此需要使用磁盘空间来存储排序后的结果和共同的url列表。

* **哈希索引的递归分解**

使用哈希索引的递归分解也可以解决这个问题，但是需要注意内存使用的问题。

这种方法的基本思路是，将两个文件分别分成若干个小块，对每个小块进行哈希索引构建。具体步骤如下：

1. 将文件a和文件b分别分成若干个小块，每个小块大小为内存限制的一半，即2G。
2. 对于每个小块，使用哈希表来构建哈希索引，将其中的url映射到对应的小块中。
3. 对于文件a中的每个小块，检查其中的url是否在文件b的哈希索引中出现过。如果出现过，则将其加入到共同的url列表中。
4. 对于文件b中的每个小块，检查其中的url是否在文件a的哈希索引中出现过。如果出现过，则将其加入到共同的url列表中。
5. 对于共同的url列表，对其进行排序并存储到磁盘中。

需要注意的是，使用哈希索引的递归分解仍然需要使用哈希表来构建哈希索引，因此需要注意内存的使用。如果哈希表的大小超过了内存限制，就需要将其中的一部分数据保存到磁盘中。此外，由于需要将两个文件都分成若干个小块，因此需要使用磁盘空间来存储这些小块。因此，这种方法仍然需要使用大量的磁盘空间，并且可能需要进行多次磁盘读写操作，效率较低。

## 2.如何 debug，可观测性怎么做的

调试（Debug）是开发过程中非常重要的一环，它用于识别和解决程序中的问题。以下是一些常用的调试技巧和可观测性方法：

1. 打印调试信息：在代码中插入打印语句，输出变量的值、函数的执行路径等信息。通过查看打印输出，可以了解程序在运行时的状态和执行流程。
2. 使用调试工具：现代的集成开发环境（IDE）通常提供强大的调试工具，如断点调试、变量监视、堆栈跟踪等。使用这些工具可以逐步执行代码，观察变量的值变化，以及跟踪函数调用的层级关系。
3. 日志记录：在程序中添加日志记录，记录关键事件、错误信息等。日志可以帮助你追踪问题发生的时间、场景和上下文，以及在生产环境中定位和分析问题。
4. 单元测试和集成测试：编写测试用例来验证代码的正确性和预期行为。测试用例可以帮助你定位和修复问题，同时也可以作为代码变更的保护措施，确保修改不会破坏现有功能。
5. 使用调试器：一些语言和开发环境提供了交互式调试器，可以在代码中设置断点，并在断点处暂停程序的执行。通过调试器，可以逐步执行代码，检查变量的值，并观察程序的状态。

关于可观测性（Observability），它是指在生产环境中监测和理解应用程序的运行状况的能力。以下是一些常用的可观测性实践：

1. 日志记录：应用程序应该生成详细的日志，包括关键事件、错误、异常等。日志应该被结构化和记录在中央位置，以便后续检索和分析。
2. 监控指标：收集和记录应用程序的性能指标，如请求响应时间、吞吐量、资源利用率等。使用监控系统来展示和警报这些指标，以便及时发现和解决性能问题。
3. 分布式追踪：对于分布式系统，追踪请求的调用链和跨服务的性能。使用追踪系统来可视化请求的路径和延迟，以便进行性能优化和故障排查。
4. 错误追踪：捕获和记录应用程序中的错误和异常。使用错误监控系统来汇总和报告错误，以便快速发现和修复问题。
5. 调试工具和仪表板：开发和使用可观测性工具和仪表板，以便实时监控和诊断应用程序。这些工具可以提供可视化界面、图表和警报，帮助开发人员和运维人员了解应用程序的状态和健康状况。

## 3.怎么写单元测试

编写单元测试是软件开发中的一项重要任务，它可以帮助验证代码的正确性、提高代码质量，并在代码修改过程中提供反馈。下面是一般的单元测试编写过程：

1. 选择合适的单元测试框架：根据你所使用的编程语言和开发环境，选择合适的单元测试框架。常见的单元测试框架包括JUnit（Java）、pytest（Python）、JUnit（C++）等。这些框架提供了一些工具和断言方法，简化了单元测试的编写和执行过程。
2. 确定被测试的单元：明确定义要测试的单元，可以是函数、方法、类或模块等。单元测试应该专注于测试单个单元的行为和功能。
3. 编写测试用例：为被测试的单元编写测试用例，覆盖不同的输入情况和边界条件。测试用例应该是独立的、可重复执行的，并且应该能够验证单元的预期行为。
4. 设置测试环境和数据：在测试用例中设置必要的测试环境和数据，包括模拟对象、准备输入数据等。确保测试环境和数据与实际运行环境相似，并且能够复现问题和验证结果。
5. 编写断言（Assertions）：在测试用例中编写断言，用于验证被测试单元的输出是否符合预期。断言可以检查返回值、异常、状态变化等。
6. 运行测试：使用所选的单元测试框架运行测试。框架将自动运行测试用例并报告测试结果。确保所有的测试用例都被执行，并且能够正确地通过或失败。
7. 分析测试结果：分析测试结果，查看通过的测试和失败的测试。如果有测试失败，检查失败原因，并修复被测试单元的问题。
8. 维护和更新测试：随着代码的修改和演进，及时维护和更新相关的单元测试。确保测试覆盖率，并在需要时添加新的测试用例。

编写好的单元测试应该具有独立性、可重复性和可自动化执行。测试应该涵盖各种正常和异常情况，以确保代码的正确性和鲁棒性。此外，良好的单元测试应该具有清晰的命名和结构，以便于理解和维护。

记住，单元测试只是软件测试的一部分，还需要其他测试技术（如集成测试、系统测试等）来确保整体系统的质量和功能正确性。


